# transformer_solver/model.py
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.distributions import Categorical
from typing import Tuple
from tensordict import TensorDict
from dataclasses import dataclass

from common.pocat_defs import FEATURE_DIM, FEATURE_INDEX, NODE_TYPE_BATTERY, NODE_TYPE_IC, NODE_TYPE_LOAD
from common.utils.common import batchify
from .pocat_env import PocatEnv


# üí° [CaDA Ïû•Ï†ê Ï†ÅÏö© 1] PrecomputedCache ÌÅ¥ÎûòÏä§ Ï∂îÍ∞Ä
@dataclass
class PrecomputedCache:
    node_embeddings: torch.Tensor
    glimpse_key: torch.Tensor
    glimpse_val: torch.Tensor
    logit_key: torch.Tensor

    def batchify(self, num_starts: int):
        return PrecomputedCache(
            batchify(self.node_embeddings, num_starts),
            batchify(self.glimpse_key, num_starts),
            batchify(self.glimpse_val, num_starts),
            batchify(self.logit_key, num_starts),
        )

# ... (RMSNorm, Normalization, ParallelGatedMLP, FeedForward, reshape_by_headsÎäî Ïù¥Ï†ÑÍ≥º ÎèôÏùº) ...
class RMSNorm(nn.Module):
    def __init__(self, dim: int, eps: float = 1e-6):
        super().__init__()
        self.eps = eps
        self.weight = nn.Parameter(torch.ones(dim))
    def _norm(self, x):
        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)
    def forward(self, x):
        output = self._norm(x.float()).type_as(x)
        return output * self.weight

class Normalization(nn.Module):
    def __init__(self, embedding_dim, norm_type='rms', **kwargs):
        super().__init__()
        self.norm_type = norm_type
        if self.norm_type == 'layer': self.norm = nn.LayerNorm(embedding_dim)
        elif self.norm_type == 'rms': self.norm = RMSNorm(embedding_dim)
        elif self.norm_type == 'instance': self.norm = nn.InstanceNorm1d(embedding_dim, affine=True, track_running_stats=False)
        else: raise NotImplementedError
    def forward(self, x):
        if self.norm_type == 'instance': return self.norm(x.transpose(1, 2)).transpose(1, 2)
        else: return self.norm(x)

class ParallelGatedMLP(nn.Module):
    def __init__(self, hidden_size: int, **kwargs):
        super().__init__()
        inner_size = int(2 * hidden_size * 4 / 3)
        multiple_of = 256
        inner_size = multiple_of * ((inner_size + multiple_of - 1) // multiple_of)
        self.l1, self.l2, self.l3 = nn.Linear(hidden_size, inner_size, bias=False), nn.Linear(hidden_size, inner_size, bias=False), nn.Linear(inner_size, hidden_size, bias=False)
        self.act = F.silu
    def forward(self, z):
        z1, z2 = self.l1(z), self.l2(z)
        return self.l3(self.act(z1) * z2)

class FeedForward(nn.Module):
    def __init__(self, embedding_dim, ff_hidden_dim, **kwargs):
        super().__init__()
        self.W1 = nn.Linear(embedding_dim, ff_hidden_dim)
        self.W2 = nn.Linear(ff_hidden_dim, embedding_dim)
    def forward(self, input1):
        return self.W2(F.relu(self.W1(input1)))

def reshape_by_heads(qkv: torch.Tensor, head_num: int) -> torch.Tensor:
    batch_s, n = qkv.size(0), qkv.size(1)
    q_reshaped = qkv.reshape(batch_s, n, head_num, -1)
    return q_reshaped.transpose(1, 2)

# üí° ÏàòÏ†ï: multi_head_attentionÏù¥ sparse_typeÏùÑ Ïù∏ÏûêÎ°ú Î∞õÎèÑÎ°ù Î≥ÄÍ≤Ω

def multi_head_attention(q, k, v, attention_mask=None, sparse_type=None):
    batch_s, head_num, n, key_dim = q.shape
    score = torch.matmul(q, k.transpose(2, 3))
    score_scaled = score / (key_dim ** 0.5)
    
    """"""
    # attention_maskÍ∞Ä Ï†úÍ≥µÎêòÏóàÎäîÏßÄ ÌôïÏù∏Ìï©ÎãàÎã§.
    if attention_mask is not None:
        # attention_maskÏùò Ï∞®Ïõê(dimension)ÏùÑ Ïñ¥ÌÖêÏÖò Ïä§ÏΩîÏñ¥ ÌñâÎ†¨Ïóê ÎßûÍ≤å Ï°∞Ï†ïÌï©ÎãàÎã§.
        # Multi-Head AttentionÏóêÏÑúÎäî (batch, head, query_len, key_len) ÌòïÌÉúÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§.
        if attention_mask.dim() == 3:
            # (batch, query_len, key_len) -> (batch, 1, query_len, key_len)
            attention_mask = attention_mask.unsqueeze(1)
        elif attention_mask.dim() == 2:
            # (query_len, key_len) -> (batch, 1, 1, query_len, key_len)
            attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)
        
        # attention_maskÏùò Í∞íÏù¥ 0Ïù∏ Î™®Îì† ÏúÑÏπòÎ•º -infÎ°ú Ï±ÑÏõÅÎãàÎã§.
        score_scaled = score_scaled.masked_fill(attention_mask == 0, -1e9)


        
    if sparse_type == 'topk':
        # Top-K Sparse Attention
        # Ïñ¥ÌÖêÏÖò Ïä§ÏΩîÏñ¥Í∞Ä ÎÜíÏùÄ KÍ∞úÎßå ÏÑ†ÌÉùÌïòÏó¨ ÎßàÏä§ÌÅ¨ ÏÉùÏÑ±
        # üí° [ÌïµÏã¨ Î≥ÄÍ≤Ω] K Í∞íÏùÑ ÏãúÌÄÄÏä§ Í∏∏Ïù¥Ïùò Ï†àÎ∞òÏúºÎ°ú ÎèôÏ†Å Í≥ÑÏÇ∞
        #    k_top_k ÌååÎùºÎØ∏ÌÑ∞Î•º Ï†úÍ±∞ÌïòÍ≥†, score_scaledÏùò ÎßàÏßÄÎßâ Ï∞®Ïõê ÌÅ¨Í∏∞Î•º ÏÇ¨Ïö©Ìï©ÎãàÎã§.
        seq_len = score_scaled.size(-1)
        k_for_topk = max(1, seq_len // 2) # ÏµúÏÜå 1Í∞úÎ•º Î≥¥Ïû•ÌïòÎ©¥ÏÑú Ï†àÎ∞òÏùÑ ÏÑ†ÌÉù

        # Ïñ¥ÌÖêÏÖò Ïä§ÏΩîÏñ¥Í∞Ä ÎÜíÏùÄ KÍ∞úÎßå ÏÑ†ÌÉùÌïòÏó¨ ÎßàÏä§ÌÅ¨ ÏÉùÏÑ±
        top_k_values, top_k_indices = torch.topk(score_scaled, k=k_for_topk, dim=-1)
        
        # ÏÑ†ÌÉùÎêòÏßÄ ÏïäÏùÄ ÎÇòÎ®∏ÏßÄ Í∞íÎì§ÏùÄ -infÎ°ú ÎßàÏä§ÌÇπ
        topk_mask = torch.zeros_like(score_scaled, dtype=torch.bool).scatter_(-1, top_k_indices, True)
        attention_weights = score_scaled.masked_fill(~topk_mask, -float('inf'))
        weights = nn.Softmax(dim=3)(attention_weights)
    else:
        # Standard (Dense) Attention
        weights = nn.Softmax(dim=3)(score_scaled)
        
    out = torch.matmul(weights, v)
    out_transposed = out.transpose(1, 2)
    return out_transposed.contiguous().view(batch_s, n, head_num * key_dim)

# üí° ÏàòÏ†ï: EncoderLayerÍ∞Ä sparse_typeÏùÑ Ïù∏ÏûêÎ°ú Î∞õÎèÑÎ°ù Î≥ÄÍ≤Ω
class EncoderLayer(nn.Module):
    def __init__(self, embedding_dim, head_num, qkv_dim, ffd='siglu', use_sparse=False, **model_params):
        super().__init__()
        self.embedding_dim, self.head_num, self.qkv_dim = embedding_dim, head_num, qkv_dim
        self.Wq, self.Wk, self.Wv = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False), nn.Linear(embedding_dim, head_num * qkv_dim, bias=False), nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)
        self.multi_head_combine = nn.Linear(head_num * qkv_dim, embedding_dim)
        self.normalization1 = Normalization(embedding_dim, **model_params)
        if ffd == 'siglu': self.feed_forward = ParallelGatedMLP(hidden_size=embedding_dim, **model_params)
        else: self.feed_forward = FeedForward(embedding_dim=embedding_dim, **model_params)
        self.normalization2 = Normalization(embedding_dim, **model_params)
        self.use_sparse = use_sparse

    def forward(self, x: torch.Tensor, attention_mask: torch.Tensor = None) -> torch.Tensor:
        q, k, v = reshape_by_heads(self.Wq(x), self.head_num), reshape_by_heads(self.Wk(x), self.head_num), reshape_by_heads(self.Wv(x), self.head_num)
        sparse_type = 'topk' if self.use_sparse else None
        mha_out = self.multi_head_combine(multi_head_attention(q, k, v, attention_mask=attention_mask, sparse_type=sparse_type))
        h = self.normalization1(x + mha_out)
        return self.normalization2(h + self.feed_forward(h))

class PocatPromptNet(nn.Module):
    def __init__(self, embedding_dim: int, num_nodes: int, **kwargs):
        super().__init__()
        # 1. Ïä§ÏπºÎùº Ï†úÏïΩÏ°∞Í±¥(4Í∞ú)ÏùÑ ÏúÑÌïú ÎÑ§Ìä∏ÏõåÌÅ¨
        self.scalar_net = nn.Sequential(
            nn.Linear(4, embedding_dim // 2),
            nn.ReLU(),
            nn.Linear(embedding_dim // 2, embedding_dim // 2)
        )
        
        # 2. ÏãúÌÄÄÏä§ Ï†úÏïΩ ÌñâÎ†¨(num_nodes * num_nodes)ÏùÑ ÏúÑÌïú ÎÑ§Ìä∏ÏõåÌÅ¨
        self.matrix_net = nn.Sequential(
            nn.Linear(num_nodes * num_nodes, embedding_dim),
            nn.ReLU(),
            nn.Linear(embedding_dim, embedding_dim // 2)
        )
        
        # 3. Í≤∞Ìï©Îêú ÏûÑÎ≤†Îî©ÏùÑ ÏµúÏ¢Ö Ï≤òÎ¶¨ÌïòÎäî ÎÑ§Ìä∏ÏõåÌÅ¨
        self.final_processor = nn.Sequential(
            nn.Linear(embedding_dim, embedding_dim), # (emb/2 + emb/2) -> emb
            nn.LayerNorm(embedding_dim),
            nn.ReLU()
        )

    def forward(self, scalar_features: torch.Tensor, matrix_features: torch.Tensor) -> torch.Tensor:
        # Í∞Å ÎÑ§Ìä∏ÏõåÌÅ¨Î•º ÌÜµÍ≥ºÏãúÏºú ÏûÑÎ≤†Îî© ÏÉùÏÑ±
        scalar_embedding = self.scalar_net(scalar_features)
        
        # ÌñâÎ†¨ÏùÑ 1Ï∞®ÏõêÏúºÎ°ú ÌéºÏ≥êÏÑú ÏûÖÎ†•
        batch_size = matrix_features.shape[0]
        matrix_flat = matrix_features.view(batch_size, -1)
        matrix_embedding = self.matrix_net(matrix_flat)
        
        # Îëê ÏûÑÎ≤†Îî©ÏùÑ Ïó∞Í≤∞(concatenate)
        combined_embedding = torch.cat([scalar_embedding, matrix_embedding], dim=-1)
        
        # ÏµúÏ¢Ö ÌîÑÎ°¨ÌîÑÌä∏ ÏûÑÎ≤†Îî© ÏÉùÏÑ±
        final_prompt_embedding = self.final_processor(combined_embedding)
        
        # (batch, 1, embedding_dim) ÌòïÌÉúÎ°ú Î¶¨ÌÑ¥
        return final_prompt_embedding.unsqueeze(1)


# üí° ÏàòÏ†ï: PocatEncoderÎ•º CaDAÏôÄ Í∞ôÏùÄ ÎìÄÏñº Ïñ¥ÌÖêÏÖò Íµ¨Ï°∞Î°ú Î≥ÄÍ≤Ω
class PocatEncoder(nn.Module):
    def __init__(self, embedding_dim: int, encoder_layer_num: int = 6, **model_params):
        super().__init__()
        # << ÏàòÏ†ï: Îã®Ïùº ÏûÑÎ≤†Îî© Î†àÏù¥Ïñ¥Î•º Ï†úÍ±∞ÌïòÍ≥†, ÎÖ∏Îìú Ïú†ÌòïÎ≥Ñ Î†àÏù¥Ïñ¥Î•º Ï∂îÍ∞ÄÌï©ÎãàÎã§.
        # self.embedding_layer = nn.Linear(FEATURE_DIM, embedding_dim)
        self.embedding_battery = nn.Linear(FEATURE_DIM, embedding_dim)
        self.embedding_ic = nn.Linear(FEATURE_DIM, embedding_dim)
        self.embedding_load = nn.Linear(FEATURE_DIM, embedding_dim)        
        
        # Sparse ÌååÎùºÎØ∏ÌÑ∞Î•º Î≥µÏÇ¨ÌïòÏó¨ ÏàòÏ†ï
        sparse_params = model_params.copy(); sparse_params['use_sparse'] = True
        global_params = model_params.copy(); global_params['use_sparse'] = False
        self.sparse_layers = nn.ModuleList([EncoderLayer(embedding_dim=embedding_dim, **sparse_params) for _ in range(encoder_layer_num)])
        self.global_layers = nn.ModuleList([EncoderLayer(embedding_dim=embedding_dim, **global_params) for _ in range(encoder_layer_num)])
        self.sparse_fusion = nn.ModuleList([nn.Linear(embedding_dim, embedding_dim) for _ in range(encoder_layer_num)])
        self.global_fusion = nn.ModuleList([nn.Linear(embedding_dim, embedding_dim) for _ in range(encoder_layer_num - 1)])

    def _create_connectivity_mask(self, td: TensorDict) -> torch.Tensor:
        nodes = td['nodes']
        batch_size, num_nodes, _ = nodes.shape
        node_types = nodes[0, :, :FEATURE_INDEX["node_type"][1]].argmax(-1)
        is_parent = (node_types == NODE_TYPE_IC) | (node_types == NODE_TYPE_BATTERY)
        is_child = (node_types == NODE_TYPE_IC) | (node_types == NODE_TYPE_LOAD)
        parent_mask = is_parent.unsqueeze(0).unsqueeze(2).expand(batch_size, num_nodes, num_nodes)
        child_mask = is_child.unsqueeze(0).unsqueeze(1).expand(batch_size, num_nodes, num_nodes)
        parent_vout_min, parent_vout_max = nodes[:, :, FEATURE_INDEX["vout_min"]].unsqueeze(2), nodes[:, :, FEATURE_INDEX["vout_max"]].unsqueeze(2)
        child_vin_min, child_vin_max = nodes[:, :, FEATURE_INDEX["vin_min"]].unsqueeze(1), nodes[:, :, FEATURE_INDEX["vin_max"]].unsqueeze(1)
        voltage_compatible = (parent_vout_min <= child_vin_max) & (parent_vout_max >= child_vin_min)
        mask = parent_mask & child_mask & voltage_compatible
        mask.diagonal(dim1=-2, dim2=-1).fill_(False)
        return mask

    def forward(self, td: TensorDict, prompt_embedding: torch.Tensor) -> torch.Tensor:
        node_features = td['nodes']
        batch_size, num_nodes, _ = node_features.shape

        # << ÏàòÏ†ï: ÎÖ∏Îìú Ïú†ÌòïÏóê Îî∞Îùº Í∞ÅÍ∏∞ Îã§Î•∏ ÏûÑÎ≤†Îî© Î†àÏù¥Ïñ¥Î•º Ï†ÅÏö©Ìï©ÎãàÎã§.
        # 1. ÎÖ∏Îìú Ïú†Ìòï Ïù∏Îç±Ïä§Î•º Ï∂îÏ∂úÌï©ÎãàÎã§.
        node_type_indices = node_features[:, :, FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(dim=-1)
        
        # 2. Í∞Å ÎÖ∏Îìú Ïú†ÌòïÏóê ÎåÄÌïú ÎßàÏä§ÌÅ¨Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
        battery_mask = (node_type_indices == NODE_TYPE_BATTERY)
        ic_mask = (node_type_indices == NODE_TYPE_IC)
        load_mask = (node_type_indices == NODE_TYPE_LOAD)
        
        # 3. ÏµúÏ¢Ö ÏûÑÎ≤†Îî©ÏùÑ Îã¥ÏùÑ ÌÖêÏÑúÎ•º Ï¥àÍ∏∞ÌôîÌï©ÎãàÎã§.
        node_embeddings = torch.zeros(batch_size, num_nodes, self.embedding_battery.out_features, device=node_features.device)
        
        # 4. ÎßàÏä§ÌÅ¨Î•º ÏÇ¨Ïö©ÌïòÏó¨ Í∞Å ÎÖ∏Îìú Ïú†ÌòïÏóê ÎßûÎäî ÏûÑÎ≤†Îî©ÏùÑ Ï†ÅÏö©ÌïòÍ≥† Í≤∞Í≥ºÎ•º Ìï©Ïπ©ÎãàÎã§.
        #    (Ìï¥ÎãπÌïòÎäî ÎÖ∏ÎìúÍ∞Ä ÏóÜÎäî Í≤ΩÏö∞ÏóêÎèÑ ÏóêÎü¨ ÏóÜÏù¥ ÎèôÏûëÌïòÎèÑÎ°ù if-any Ï≤¥ÌÅ¨)
        if battery_mask.any():
            node_embeddings[battery_mask] = self.embedding_battery(node_features[battery_mask])
        if ic_mask.any():
            node_embeddings[ic_mask] = self.embedding_ic(node_features[ic_mask])
        if load_mask.any():
            node_embeddings[load_mask] = self.embedding_load(node_features[load_mask])
        
        connectivity_mask = self._create_connectivity_mask(td)
        global_input = torch.cat((node_embeddings, prompt_embedding), dim=1)
        global_attention_mask = torch.ones(batch_size, num_nodes + 1, num_nodes + 1, dtype=torch.bool, device=node_embeddings.device)
        global_attention_mask[:, :num_nodes, :num_nodes] = connectivity_mask
        sparse_out, global_out = node_embeddings, global_input


        
        for i in range(len(self.sparse_layers)):
            # üí° [ÌïµÏã¨ ÏàòÏ†ï] Sparse StreamÏóê 'connectivity_mask'Î•º Ï†ÑÎã¨Ìï©ÎãàÎã§.
            sparse_out = self.sparse_layers[i](sparse_out, attention_mask=connectivity_mask)
            
            # Global Stream: Ïó∞Í≤∞ÏÑ± ÎßàÏä§ÌÅ¨ Í∏∞Î∞ò Ïñ¥ÌÖêÏÖò
            global_out = self.global_layers[i](global_out, attention_mask=global_attention_mask)
            
            # Fusion
            sparse_out = sparse_out + self.sparse_fusion[i](global_out[:, :num_nodes])
            if i < len(self.global_layers) - 1:
                global_nodes = global_out[:, :num_nodes] + self.global_fusion[i](sparse_out)
                global_out = torch.cat((global_nodes, global_out[:, num_nodes:]), dim=1)  
        return sparse_out


# üí° [CaDA Ïû•Ï†ê Ï†ÅÏö© 2] ÎîîÏΩîÎçî Î°úÏßÅ ÏàòÏ†ï
class PocatDecoder(nn.Module):
    def __init__(self, embedding_dim, head_num, qkv_dim, **model_params):
        super().__init__()
        self.embedding_dim = embedding_dim
        self.head_num = head_num
        self.qkv_dim = qkv_dim

        self.Wk = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)
        self.Wv = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)
        self.Wk_logit = nn.Linear(embedding_dim, embedding_dim, bias=False)

        
        # ÏøºÎ¶¨ ÏÉùÏÑ±Ïö© Linear Î†àÏù¥Ïñ¥: ÏÉÅÌÉú Ï†ïÎ≥¥Î•º Ï∂îÍ∞ÄÎ°ú ÏûÖÎ†•Î∞õÏùå
        # ÏÉÅÌÉú Î≤°ÌÑ∞ Ï∞®Ïõê: 1 (ic_current_draw) + 1 (main_tree_mask) + 1 (unconnected_loads_mask) = 3
        # Phase 0: main_tree context + Ï†ÑÏó≠ ÏÉÅÌÉú
        self.Wq_load_select = nn.Linear(embedding_dim + 3, head_num * qkv_dim, bias=False)
        # Phase 1: trajectory head + Ï†ÑÏó≠ ÏÉÅÌÉú
        self.Wq_parent_select = nn.Linear(embedding_dim + 3, head_num * qkv_dim, bias=False)
        
        self.multi_head_combine = nn.Linear(head_num * qkv_dim, embedding_dim)

    def forward(self, td: TensorDict, cache: PrecomputedCache):
        # 1. PhaseÏóê Îî∞Îùº Ïª®ÌÖçÏä§Ìä∏ÏôÄ ÏøºÎ¶¨ ÏÉùÏÑ±
        phase = td["decoding_phase"][0, 0].item()
        
        # üí° [CaDA Ïû•Ï†ê Ï†ÅÏö© 3] ÎèôÏ†Å ÏÉÅÌÉú(State) Í∏∞Î∞ò ÏøºÎ¶¨ ÏÉùÏÑ±
        # ÌòÑÏû¨ Ï†ÑÎ†•ÎßùÏùò ÏÉÅÌÉú Ï†ïÎ≥¥Î•º ÏßëÍ≥Ñ
        avg_current_draw = td["ic_current_draw"].mean(dim=1, keepdim=True)
        main_tree_ratio = td["main_tree_mask"].float().mean(dim=1, keepdim=True)
        unconnected_ratio = td["unconnected_loads_mask"].float().mean(dim=1, keepdim=True)
        
        state_features = torch.cat([avg_current_draw, main_tree_ratio, unconnected_ratio], dim=1)

        if phase == 0:
            # Phase 0: Ï£º Ï†ÑÎ†•ÎßùÏùò ÌèâÍ∑† ÏûÑÎ≤†Îî©ÏùÑ Ïª®ÌÖçÏä§Ìä∏Î°ú ÏÇ¨Ïö©
            main_tree_nodes = cache.node_embeddings * td["main_tree_mask"].unsqueeze(-1)
            context = main_tree_nodes.sum(1) / (td["main_tree_mask"].sum(1, keepdim=True) + 1e-9)
            # Ïª®ÌÖçÏä§Ìä∏ÏôÄ ÏÉÅÌÉú Ï†ïÎ≥¥Î•º Í≤∞Ìï©ÌïòÏó¨ ÏøºÎ¶¨ ÏÉùÏÑ±
            query_input = torch.cat([context, state_features], dim=1)
            q = reshape_by_heads(self.Wq_load_select(query_input.unsqueeze(1)), self.head_num)
        else: # phase == 1
            # Phase 1: ÌòÑÏû¨ Í≤ΩÎ°úÏùò ÎÅù(Head) ÎÖ∏Îìú ÏûÑÎ≤†Îî©ÏùÑ Ïª®ÌÖçÏä§Ìä∏Î°ú ÏÇ¨Ïö©
            trajectory_head_idx = td["trajectory_head"].squeeze(-1)
            head_emb = cache.node_embeddings[torch.arange(td.batch_size[0]), trajectory_head_idx]
            # Ïª®ÌÖçÏä§Ìä∏ÏôÄ ÏÉÅÌÉú Ï†ïÎ≥¥Î•º Í≤∞Ìï©ÌïòÏó¨ ÏøºÎ¶¨ ÏÉùÏÑ±
            query_input = torch.cat([head_emb, state_features], dim=1)
            q = reshape_by_heads(self.Wq_parent_select(query_input.unsqueeze(1)), self.head_num)
        
        # 2. Multi-Head Attention ÏàòÌñâ
        mha_out = multi_head_attention(q, cache.glimpse_key, cache.glimpse_val)
        mh_atten_out = self.multi_head_combine(mha_out)
        
        # 3. ÏµúÏ¢Ö Logits Í≥ÑÏÇ∞ (Single-Head Attention)
        scores = torch.matmul(mh_atten_out, cache.logit_key).squeeze(1) / (self.embedding_dim ** 0.5)
        
        return scores

class PocatModel(nn.Module):
    def __init__(self, **model_params):
        super().__init__()
        self.prompt_net = PocatPromptNet(embedding_dim=model_params['embedding_dim'], num_nodes=model_params['num_nodes'])
        self.encoder = PocatEncoder(**model_params)
        self.decoder = PocatDecoder(**model_params)
        # üí° [CaDA Ïû•Ï†ê Ï†ÅÏö© 4] GRUCell Ï†úÍ±∞ (ÏÉÅÌÉú Í∏∞Î∞ò ÏøºÎ¶¨Î°ú ÎåÄÏ≤¥)
        # self.context_gru = nn.GRUCell(model_params['embedding_dim'] * 2, model_params['embedding_dim'])

    def forward(self, td: TensorDict, env: PocatEnv, decode_type: str = 'greedy', pbar: object = None, status_msg: str = "", log_fn=None):
        base_desc = pbar.desc.split(' | ')[0] if pbar else ""
        
        if pbar:
            desc = f"{base_desc} | {status_msg} | ‚ñ∂ Encoding (ing..)"
            pbar.set_description(desc)
            if log_fn: log_fn(desc)
        
        # 1. Ïù∏ÏΩîÎî©
        prompt_embedding = self.prompt_net(td["scalar_prompt_features"], td["matrix_prompt_features"])
        encoded_nodes = self.encoder(td, prompt_embedding)        

        # üí° [CaDA Ïû•Ï†ê Ï†ÅÏö© 5] ÎîîÏΩîÎî© ÏãúÏûë Ï†Ñ Key, Value ÏÇ¨Ï†Ñ Í≥ÑÏÇ∞ Î∞è Ï∫êÏã±
        # ÎîîÏΩîÎçîÏóêÏÑú ÏÇ¨Ïö©Ìï† Key, ValueÎ•º ÎØ∏Î¶¨ Í≥ÑÏÇ∞
        glimpse_key = reshape_by_heads(self.decoder.Wk(encoded_nodes), self.decoder.head_num)
        glimpse_val = reshape_by_heads(self.decoder.Wv(encoded_nodes), self.decoder.head_num)
        logit_key = encoded_nodes.transpose(1, 2) # Single-head attentionÏö©
        
        cache = PrecomputedCache(encoded_nodes, glimpse_key, glimpse_val, logit_key)

        # 2. ÎîîÏΩîÎî© Ï§ÄÎπÑ (POMO)
        num_starts, start_nodes_idx = env.select_start_nodes(td)
        node_names = env.generator.config.node_names
        num_total_loads = env.generator.num_loads
        
        batch_size = td.batch_size[0]
        td = batchify(td, num_starts)
        # Ï∫êÏãúÎèÑ POMOÏóê ÎßûÍ≤å ÌôïÏû•
        cache = cache.batchify(num_starts)
        
        expanded_batch_size = td.batch_size[0]
        log_probs, actions = [], []
        
        # 3. Ï≤´ Î≤àÏß∏ Ïï°ÏÖò(Load ÏÑ†ÌÉù) Î∞è ÌôòÍ≤Ω Ï¥àÍ∏∞Ìôî
        action_part1 = start_nodes_idx.repeat(batch_size)
        action_part2 = torch.zeros_like(action_part1)
        action = torch.stack([action_part1, action_part2], dim=1)
        
        td.set("action", action)
        output_td = env.step(td)
        td = output_td["next"]
        actions.append(action)
        log_probs.append(torch.zeros(expanded_batch_size, device=td.device))
        
        decoding_step = 0
        while not td["done"].all():
            decoding_step += 1
            num_connected_loads = num_total_loads - td["unconnected_loads_mask"][0].sum().item()
            phase = td["decoding_phase"][0, 0].item()

            state_description = ""
            if phase == 0:
                state_description = "Select New Load"
            else:
                current_node_idx = td["trajectory_head"][0].item()
                if current_node_idx != -1:
                    current_node_name = node_names[current_node_idx]
                    state_description = f"Find Parent for '{current_node_name}'"

            if pbar and log_fn:
                log_fn(f"{base_desc} | ... | Decoding (Step {decoding_step} State): {state_description}")

            scores = self.decoder(td, cache)
            mask = env.get_action_mask(td)

            # << ÏàòÏ†ï: selected_prob Î≥ÄÏàòÎ•º Î£®ÌîÑ ÏãúÏûë Ï†ÑÏóê ÏÑ†Ïñ∏ >>
            selected_prob = None

            if phase == 0:
                mask_for_load_select = mask[:, :, 0]
                scores.masked_fill_(~mask_for_load_select, -float('inf'))
                log_prob = F.log_softmax(scores, dim=-1)

                probs = log_prob.exp()
                selected_load = Categorical(probs=probs).sample() if decode_type == 'sampling' else probs.argmax(dim=-1)
                action = torch.stack([selected_load, torch.zeros_like(selected_load)], dim=1)
                log_prob_val = log_prob.gather(1, selected_load.unsqueeze(-1)).squeeze(-1)
                selected_prob = probs.gather(1, selected_load.unsqueeze(-1)).squeeze(-1)


            else: # phase == 1
                trajectory_head_idx = td["trajectory_head"].squeeze(-1)
                mask_for_parent_select = mask[torch.arange(expanded_batch_size), trajectory_head_idx, :]

                scores.masked_fill_(~mask_for_parent_select, -float('inf'))
                log_prob = F.log_softmax(scores, dim=-1)
                probs = log_prob.exp()
                selected_parent_idx = Categorical(probs=probs).sample() if decode_type == 'sampling' else probs.argmax(dim=-1)
                action = torch.stack([trajectory_head_idx, selected_parent_idx], dim=1)
                log_prob_val = log_prob.gather(1, selected_parent_idx.unsqueeze(-1)).squeeze(-1)
                selected_prob = probs.gather(1, selected_parent_idx.unsqueeze(-1)).squeeze(-1)


            if pbar:
                child_idx = action[0, 0].item()
                parent_idx = action[0, 1].item()
                child_name = node_names[child_idx]
                parent_name = node_names[parent_idx]
                
                # << ÏàòÏ†ï: Î°úÍ∑∏ Î©îÏãúÏßÄÏóê ÏÑ†ÌÉù ÌôïÎ•†ÏùÑ Ìè¨Ìï®ÌïòÎèÑÎ°ù Î≥ÄÍ≤Ω >>
                prob_val = selected_prob[0].item() if selected_prob is not None else 0
                action_description = ""

                if phase == 0:
                    action_description = f"Started new path with Load '{child_name}' (Prob: {prob_val:.2%})"
                else:
                    parent_idx = action[0, 1].item()
                    parent_name = node_names[parent_idx]
                    action_description = f"Connected '{child_name}' to '{parent_name}' (Prob: {prob_val:.2%})"
                
                detail_msg = f"‚óÄ Decoding ({num_connected_loads}/{num_total_loads} Loads, Step {decoding_step}): {action_description}"
                desc = f"{base_desc} | {status_msg} | ‚ñ∂ Encoding (done) | {detail_msg}"
                pbar.set_description(desc)
                if log_fn: log_fn(desc)

            td.set("action", action)
            output_td = env.step(td)
            td = output_td["next"]
            
            actions.append(action)
            log_probs.append(log_prob_val)

            

        final_reward = output_td["reward"]

        return {
            "reward": final_reward,
            "log_likelihood": torch.stack(log_probs, 1).sum(1) if log_probs else torch.zeros(expanded_batch_size, device=td.device),
            "actions": torch.stack(actions, 1) if actions else torch.empty(expanded_batch_size, 0, 2, dtype=torch.long, device=td.device)
        }
