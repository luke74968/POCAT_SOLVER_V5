# transformer_solver/pocat_env.py

import torch
from tensordict import TensorDict
from torchrl.envs import EnvBase
from typing import Optional, List

from torchrl.data import Unbounded , UnboundedDiscrete
from torchrl.data import CompositeSpec



from common.pocat_defs import (
    SCALAR_PROMPT_FEATURE_DIM, FEATURE_DIM, FEATURE_INDEX,
    NODE_TYPE_BATTERY, NODE_TYPE_IC, NODE_TYPE_LOAD
)

BATTERY_NODE_IDX = 0

class PocatEnv(EnvBase):
    name = "pocat"

    def __init__(self, generator_params: dict = {}, device: str = "cpu", **kwargs):
        super().__init__(device=device)
        from .pocat_generator import PocatGenerator
        self.generator = PocatGenerator(**generator_params)
        self._make_spec()
        self._set_seed(None) # ìƒì„±ìì—ì„œ í˜¸ì¶œì€ ë˜ì–´ ìˆìœ¼ë‚˜, ì•„ë˜ì— ë©”ì†Œë“œ ì •ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.
        self.trajectory_head_stacks: List[List[int]] = []


    def _make_spec(self):
        """í™˜ê²½ì˜ observation, action, reward ìŠ¤í™ì„ ì •ì˜í•©ë‹ˆë‹¤."""
        num_nodes = self.generator.num_nodes
        
        self.observation_spec = CompositeSpec({
            "nodes": Unbounded(shape=(num_nodes, FEATURE_DIM)),
            "scalar_prompt_features": Unbounded(shape=(SCALAR_PROMPT_FEATURE_DIM,)),
            "matrix_prompt_features": Unbounded(shape=(num_nodes, num_nodes)),
            "connectivity_matrix": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.bool),
            "adj_matrix": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.bool),
            "unconnected_loads_mask": Unbounded(shape=(num_nodes,), dtype=torch.bool),
            "trajectory_head": UnboundedDiscrete(shape=(1,)),
            "step_count": UnboundedDiscrete(shape=(1,)),
            "node_stages": UnboundedDiscrete(shape=(num_nodes,)),
        })
        
        self.action_spec = UnboundedDiscrete(shape=(1,))
        self.reward_spec = Unbounded(shape=(1,))

    def _set_seed(self, seed: Optional[int] = None):
        if seed is not None:
            torch.manual_seed(seed)

    def select_start_nodes(self, td: TensorDict):
        node_types = td["nodes"][0, :, FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
        start_nodes_idx = torch.where(node_types == NODE_TYPE_LOAD)[0]
        return len(start_nodes_idx), start_nodes_idx
    
    def _trace_path_batch(self, b_idx, start_nodes, adj_matrix):
        """ë°°ì¹˜ ì „ì²´ì— ëŒ€í•´ start_nodeë“¤ì˜ ëª¨ë“  ì¡°ìƒì„ ì°¾ì•„ ë§ˆìŠ¤í¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        num_nodes = adj_matrix.shape[-1]
        
        # ì„ íƒëœ ë°°ì¹˜ í•­ëª©ë“¤ì— ëŒ€í•œ ì¸ì ‘ í–‰ë ¬
        adj_b = adj_matrix[b_idx]
        
        # ê²½ë¡œ ë§ˆìŠ¤í¬ ì´ˆê¸°í™” (ì‹œì‘ ë…¸ë“œë§Œ True)
        path_mask = torch.zeros(len(b_idx), num_nodes, dtype=torch.bool, device=self.device)
        path_mask[torch.arange(len(b_idx)), start_nodes] = True
        
        # í–‰ë ¬ ê³±ì…ˆì„ ì´ìš©í•´ ê·¸ë˜í”„ë¥¼ ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°€ë©° ëª¨ë“  ì¡°ìƒì„ ì°¾ìŠµë‹ˆë‹¤.
        for _ in range(num_nodes):
            # í˜„ì¬ ê²½ë¡œì— í¬í•¨ëœ ë…¸ë“œë“¤ì˜ ë¶€ëª¨ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            parents_mask = (adj_b.float() @ path_mask.float().unsqueeze(-1)).squeeze(-1) > 0
            # ë” ì´ìƒ ìƒˆë¡œìš´ ë¶€ëª¨ê°€ ì—†ìœ¼ë©´ (ê²½ë¡œì˜ ëì— ë„ë‹¬í•˜ë©´) ì¢…ë£Œí•©ë‹ˆë‹¤.
            if (parents_mask & ~path_mask).sum() == 0: break
            # ìƒˆë¡œ ì°¾ì€ ë¶€ëª¨ë“¤ì„ ê²½ë¡œ ë§ˆìŠ¤í¬ì— ì¶”ê°€í•©ë‹ˆë‹¤.
            path_mask |= parents_mask
        return path_mask            

    def _reset(self, td: Optional[TensorDict] = None, **kwargs) -> TensorDict:
        batch_size = kwargs.get("batch_size", self.batch_size)
        if isinstance(batch_size, tuple): batch_size = batch_size[0]
        
        td_initial = self.generator(batch_size=batch_size).to(self.device)
        num_nodes = td_initial["nodes"].shape[1]

        self.trajectory_head_stacks = [[] for _ in range(batch_size)]

        # --- ğŸ’¡ 1. Trajectory ê¸°ë°˜ ìƒíƒœ(state) ì¬ì •ì˜ ---
        reset_td = TensorDict({
            "nodes": td_initial["nodes"],
            "scalar_prompt_features": td_initial["scalar_prompt_features"],
            "matrix_prompt_features": td_initial["matrix_prompt_features"],
            "connectivity_matrix": td_initial["connectivity_matrix"],
            "adj_matrix": torch.zeros(batch_size, num_nodes, num_nodes, dtype=torch.bool, device=self.device),
            "trajectory_head": torch.full((batch_size, 1), BATTERY_NODE_IDX, dtype=torch.long, device=self.device),
            "unconnected_loads_mask": torch.ones(batch_size, num_nodes, dtype=torch.bool, device=self.device),
            "step_count": torch.zeros(batch_size, 1, dtype=torch.long, device=self.device),
            "node_stages": torch.full((batch_size, num_nodes), -1, dtype=torch.long, device=self.device),
        }, batch_size=[batch_size], device=self.device)
        
        reset_td["node_stages"][:, BATTERY_NODE_IDX] = 0
        
        # ë°°í„°ë¦¬(ì¸ë±ìŠ¤ 0)ëŠ” í•­ìƒ ë©”ì¸ íŠ¸ë¦¬ì— í¬í•¨
        node_types = td_initial["nodes"][0, :, FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
        is_load = node_types == NODE_TYPE_LOAD
        reset_td["unconnected_loads_mask"][:, ~is_load] = False
        reset_td.set("done", torch.zeros(batch_size, 1, dtype=torch.bool, device=self.device))
        return reset_td

    # ğŸ’¡ ì¶”ê°€ëœ step ë©”ì†Œë“œ: ë°°ì¹˜ í¬ê¸° ê²€ì‚¬ë¥¼ ìš°íšŒí•©ë‹ˆë‹¤.
    def step(self, tensordict: TensorDict) -> TensorDict:
        return self._step(tensordict)

    def _calculate_power_loss(self, ic_node_feature: torch.Tensor, i_out: float) -> float:
        ic_type = ic_node_feature[FEATURE_INDEX["ic_type_idx"]].item()
        vin = ic_node_feature[FEATURE_INDEX["vin_min"]].item()
        vout = ic_node_feature[FEATURE_INDEX["vout_min"]].item()
        if ic_type == 1.0: # LDO
            op_current = ic_node_feature[FEATURE_INDEX["op_current"]].item()
            return (vin - vout) * i_out + vin * op_current
        elif ic_type == 2.0: # Buck
            s, e = FEATURE_INDEX["efficiency_params"]
            a, b, c = ic_node_feature[s:e]
            return a * (i_out**2) + b * i_out + c
        return 0


    def _step(self, td: TensorDict) -> TensorDict:
        new_batch_size = td.batch_size[0]
        if new_batch_size > len(self.trajectory_head_stacks):
            num_repeats = new_batch_size // len(self.trajectory_head_stacks)
            self.trajectory_head_stacks = [
                stack.copy() for stack in self.trajectory_head_stacks for _ in range(num_repeats)
            ]

        action = td["action"].squeeze(-1)
        current_head = td["trajectory_head"].squeeze(-1)
        next_obs = td.clone()
        batch_size = td.batch_size[0]
        num_nodes = td["nodes"].shape[1]
        
        for i in range(batch_size):
            head, act = current_head[i].item(), action[i].item()
            if head == BATTERY_NODE_IDX:
                load_idx_in_config = act - (1 + self.generator.num_ics)
                load_info = self.generator.config.loads[load_idx_in_config]
                if load_info.get("independent_rail_type") is not None:
                    self.trajectory_head_stacks[i].append(head)
                next_obs["trajectory_head"][i] = act
                next_obs["unconnected_loads_mask"][i, act] = False
            else:
                child_idx, parent_idx = head, act
                next_obs["adj_matrix"][i, parent_idx, child_idx] = True
                parent_stage = next_obs["node_stages"][i, parent_idx].item()
                next_obs["node_stages"][i, child_idx] = parent_stage + 1
                
                is_parent_connected = (parent_idx == BATTERY_NODE_IDX) or \
                                      (next_obs["adj_matrix"][i, :, parent_idx].any())
                
                if is_parent_connected:
                    if self.trajectory_head_stacks[i]:
                        next_obs["trajectory_head"][i] = self.trajectory_head_stacks[i].pop()
                    else:
                        next_obs["trajectory_head"][i] = BATTERY_NODE_IDX
                else:
                    next_obs["trajectory_head"][i] = parent_idx
        
        # ì „ë¥˜ ë° ì˜¨ë„ ì—…ë°ì´íŠ¸ (ë°°ì¹˜ ì—°ì‚°)
        new_current_out = (next_obs["adj_matrix"].float().transpose(-1, -2) @ \
                           next_obs["nodes"][:, :, FEATURE_INDEX["current_active"]].float().unsqueeze(-1)).squeeze(-1)
        next_obs["nodes"][:, :, FEATURE_INDEX["current_out"]] = new_current_out
        
        ambient_temp = self.generator.config.constraints.get("ambient_temperature", 25.0)
        for i in range(batch_size):
            for n_idx in range(num_nodes):
                node_feat = next_obs["nodes"][i, n_idx]
                if node_feat[FEATURE_INDEX["node_type"][0]+NODE_TYPE_IC]:
                    power_loss = self._calculate_power_loss(node_feat, new_current_out[i, n_idx].item())
                    theta_ja = node_feat[FEATURE_INDEX["theta_ja"]].item()
                    next_obs["nodes"][i, n_idx, FEATURE_INDEX["junction_temp"]] = ambient_temp + power_loss * theta_ja
        
        next_obs.set("step_count", td["step_count"] + 1)
        all_loads_connected = (next_obs["unconnected_loads_mask"].sum(dim=1) == 0)
        is_done = all_loads_connected & (next_obs["trajectory_head"].squeeze(-1) == BATTERY_NODE_IDX)
        
        return TensorDict({"next": next_obs, "reward": self.get_reward(next_obs, is_done), "done": is_done.unsqueeze(-1)}, batch_size=td.batch_size)

        
    # ğŸ’¡ *** ì—¬ê¸°ê°€ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ì…ë‹ˆë‹¤ ***
    def get_action_mask(self, td: TensorDict) -> torch.Tensor:
        batch_size, num_nodes, _ = td["nodes"].shape
        mask = torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device)
        current_head = td["trajectory_head"].squeeze(-1)
        load_configs = self.generator.config.loads
        num_ics = self.generator.num_ics

        b_idx = torch.arange(batch_size, device=self.device)

        # --- ğŸ‘‡ [í•µì‹¬ ìˆ˜ì •] Single-Trajectory ì•¡ì…˜ ë§ˆìŠ¤í‚¹ ë¡œì§ ---
        # Case 1: í˜„ì¬ í—¤ë“œê°€ ë°°í„°ë¦¬ -> 'ìƒˆ Load ì„ íƒ' ë§ˆìŠ¤í¬ ìƒì„±
        head_is_battery_mask = (current_head == BATTERY_NODE_IDX)
        if head_is_battery_mask.any():
            mask[head_is_battery_mask] = td["unconnected_loads_mask"][head_is_battery_mask]

        # Phase 1: í˜„ì¬ ê²½ë¡œë¥¼ ì´ì„ ë¶€ëª¨ ë…¸ë“œ ì„ íƒ
        head_is_node_mask = ~head_is_battery_mask
        if head_is_node_mask.any():
            b_select_parent = b_idx[head_is_node_mask]
            child_indices = current_head[b_select_parent]

            node_types = td["nodes"][0, :, :FEATURE_INDEX["node_type"][1]].argmax(-1)
            

            # 1. ê¸°ë³¸ ìê²© ì •ì˜: ë¶€ëª¨ëŠ” IC ë˜ëŠ” ë°°í„°ë¦¬ì—¬ì•¼ë§Œ í•¨ (Load ì›ì²œ ë°°ì œ)
            parent_candidate_mask = (node_types == NODE_TYPE_IC) | (node_types == NODE_TYPE_BATTERY)
            can_be_parent = parent_candidate_mask.unsqueeze(0).expand(len(b_idx), -1).clone()

            # 2. ì‚¬ì´í´ ë°©ì§€: í˜„ì¬ ê²½ë¡œì˜ ì¡°ìƒ ë° ìì†ì€ ë¶€ëª¨ê°€ ë  ìˆ˜ ì—†ìŒ
            #    ìê¸° ìì‹ ë„ í¬í•¨í•˜ì—¬ í™•ì‹¤íˆ ì œì™¸í•©ë‹ˆë‹¤.
            ancestor_mask = self._trace_path_batch(b_idx, child_indices, td["adj_matrix"])
            can_be_parent &= ~ancestor_mask

            # 3. ì „ì•• í˜¸í™˜ì„± ê²€ì‚¬
            is_voltage_compatible = td["connectivity_matrix"][b_idx, :, child_indices]
            can_be_parent &= is_voltage_compatible

            # 4. ì „ë¥˜ í•œê³„ ê²€ì‚¬
            current_path_mask = self._trace_path_batch(b_idx, child_indices, td["adj_matrix"])
            path_nodes_currents = (td["nodes"][b_idx, :, FEATURE_INDEX["current_active"]] * current_path_mask).sum(dim=1)
            current_draw = td["nodes"][b_idx, :, FEATURE_INDEX["current_out"]]
            prospective_draw = current_draw + path_nodes_currents.unsqueeze(1)
            parent_limits = td["nodes"][b_idx, :, FEATURE_INDEX["i_limit"]]
            can_be_parent &= (prospective_draw <= parent_limits) | (parent_limits == 0)

            # 5. ê¸°íƒ€ ì œì•½ì¡°ê±´ (Power Sequence, Independent Rail)
            constraints, loads_info, node_names = self.generator.config.constraints, self.generator.config.loads, self.generator.config.node_names
            # ancestors í…ì„œ ìƒì„± ì‹œ deviceë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
            ancestors = td["adj_matrix"][b_idx].clone().to(self.device) 
            for _ in range(num_nodes): # ìµœì•…ì˜ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ num_nodes ë§Œí¼ ë°˜ë³µ
                ancestors = ancestors | (ancestors.float() @ ancestors.float()).bool()
            
            head_load_idx = child_indices - (1 + len(self.generator.config.available_ics))

            # ì•„ë˜ì˜ forë¬¸ì€ ë°°ì¹˜ë³„ë¡œ ìˆœíšŒí•˜ë¯€ë¡œ ë³‘ë ¬ ì²˜ë¦¬ê°€ ì–´ë µì§€ë§Œ,
            # ê·¸ ì•ˆì˜ í…ì„œ ì—°ì‚°ì€ ì´ë¯¸ GPUì—ì„œ ìˆ˜í–‰ë˜ë„ë¡ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.

            for idx, b in enumerate(b_idx.tolist()):
                if 0 <= head_load_idx[idx] < len(loads_info):
                    load = loads_info[head_load_idx[idx]]
                    rail_type = load.get("independent_rail_type")
                    # << ìˆ˜ì •: ë°°í„°ë¦¬(ë…¸ë“œ 0)ëŠ” ì´ ì œì•½ì—ì„œ ì œì™¸í•˜ë„ë¡ ìˆ˜ì • >>
                    is_not_battery_mask = torch.ones(num_nodes, dtype=torch.bool, device=self.device)
                    is_not_battery_mask[0] = False
                    
                    if rail_type == "exclusive_supplier":
                        # ì´ë¯¸ ìì‹ì´ ìˆëŠ” ë…¸ë“œëŠ” ë¶€ëª¨ê°€ ë  ìˆ˜ ì—†ìŒ (ë‹¨, ë°°í„°ë¦¬ëŠ” ì˜ˆì™¸)
                        no_existing_children_mask = td["adj_matrix"][b].sum(dim=1) == 0
                        can_be_parent[idx] &= (no_existing_children_mask | ~is_not_battery_mask)
                    elif rail_type == "exclusive_path":
                        # ì´ë¯¸ ìì‹ì´ 2ê°œ ì´ìƒ ìˆëŠ” ë…¸ë“œëŠ” ë¶€ëª¨ê°€ ë  ìˆ˜ ì—†ìŒ (ë‹¨, ë°°í„°ë¦¬ëŠ” ì˜ˆì™¸)
                        less_than_two_children_mask = td["adj_matrix"][b].sum(dim=1) <= 1
                        can_be_parent[idx] &= (less_than_two_children_mask | ~is_not_battery_mask)

            
            for seq in constraints.get("power_sequences", []):
                if seq.get("f") != 1: continue
                j_name, k_name = seq.get("j"), seq.get("k")
                if j_name not in node_names or k_name not in node_names: continue
                j_idx, k_idx = node_names.index(j_name), node_names.index(k_name)
                is_head_k_mask = child_indices == k_idx
                if is_head_k_mask.any():
                    can_be_parent[is_head_k_mask] &= ~ancestors[is_head_k_mask, :, j_idx]
                        # 1. ë¶€í•˜ëŠ” ë¶€ëª¨ê°€ ë  ìˆ˜ ì—†ìŒ
            is_load = (node_types == NODE_TYPE_LOAD)
            can_be_parent &= ~is_load.unsqueeze(0)


            mask[b_idx] = can_be_parent
            
        return mask
    

    
    def get_reward(self, td: TensorDict, timed_out: torch.Tensor) -> torch.Tensor:
        """
        Calculates the reward based on the final state of the power tree.
        The reward is the negative of the total cost of used ICs.
        This function is called only when an episode is done.
        """
        reward = torch.zeros(td.batch_size[0], device=self.device)
        done = td["done"].squeeze(-1)
        
        # ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œëœ ê²½ìš°
        done_success = done & ~timed_out
        if done_success.any():
            is_used_mask = td["adj_matrix"][done_success].any(dim=1) | td["adj_matrix"][done_success].any(dim=2)
            node_costs = td["nodes"][done_success, :, FEATURE_INDEX["cost"]]
            ic_mask = td["nodes"][done_success, :, FEATURE_INDEX["node_type"][0] + NODE_TYPE_IC] == 1
            used_ic_mask = is_used_mask & ic_mask
            total_cost = (node_costs * used_ic_mask).sum(dim=-1)
            reward[done_success] = -total_cost

        # ğŸ’¡ *** ì—¬ê¸°ê°€ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ì…ë‹ˆë‹¤ (2/2) ***
        # ì‹œê°„ ì´ˆê³¼ë¡œ ì‹¤íŒ¨í•œ ê²½ìš° íŒ¨ë„í‹°ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.
        if timed_out.any():
            # ì—°ê²°í•˜ì§€ ëª»í•œ Loadì˜ ìˆ˜ë§Œí¼ í° íŒ¨ë„í‹°ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.
            unconnected_loads = td["unconnected_loads_mask"][timed_out].sum(dim=1).float()
            reward[timed_out] -= unconnected_loads * 10.0 # íŒ¨ë„í‹° ê°’
            
        return reward