# transformer_solver/pocat_env.py

import torch
from tensordict import TensorDict
from torchrl.envs import EnvBase
from typing import Optional, Tuple
from torchrl.data import Unbounded, Categorical, Composite

from .pocat_generator import PocatGenerator
from common.pocat_defs import (
    NODE_TYPE_BATTERY, NODE_TYPE_IC, NODE_TYPE_LOAD,
    FEATURE_DIM, FEATURE_INDEX, SCALAR_PROMPT_FEATURE_DIM
)

class PocatEnv(EnvBase):
    name = "pocat"

    def __init__(self, generator_params: dict = {}, device: str = "cpu", **kwargs):
        super().__init__(device=device)
        self.generator = PocatGenerator(**generator_params)
        self._make_spec()

    def _make_spec(self):
        num_nodes = self.generator.num_nodes
        
        self.observation_spec = Composite({
            "nodes": Unbounded(shape=(num_nodes, FEATURE_DIM), dtype=torch.float32),
            "scalar_prompt_features": Unbounded(shape=(SCALAR_PROMPT_FEATURE_DIM,), dtype=torch.float32),
            "matrix_prompt_features": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.float32),
            # ğŸ’¡ ì•„ë˜ ìƒíƒœë“¤ì€ ì´ì œ ëª¨ë¸ ë‚´ë¶€ì—ì„œ ê´€ë¦¬ë˜ë¯€ë¡œ ìŠ¤í™ì—ì„œ ì œê±°í•´ë„ ë¬´ë°©í•˜ì§€ë§Œ,
            #    í˜¸í™˜ì„±ì„ ìœ„í•´ ë‚¨ê²¨ë‘ê±°ë‚˜ í˜¹ì€ ì•„ë˜ _resetì—ì„œë§Œ ìƒì„±í•˜ë„ë¡ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        })
        
        self.action_spec = Unbounded(shape=(2,), dtype=torch.long)
        self.reward_spec = Unbounded(shape=(1,))

    def _set_seed(self, seed: Optional[int] = None):
        if seed is not None:
            torch.manual_seed(seed)

    def select_start_nodes(self, td: TensorDict) -> Tuple[int, torch.Tensor]:
        node_types = td["nodes"][0, :, :FEATURE_INDEX["node_type"][1]].argmax(-1)
        start_nodes_idx = torch.where(node_types == NODE_TYPE_LOAD)[0]
        num_starts = len(start_nodes_idx)
        return num_starts, start_nodes_idx

    def _reset(self, td: Optional[TensorDict] = None, **kwargs) -> TensorDict:
        if td is None:
            batch_size = kwargs.get("batch_size", self.batch_size)
            if not isinstance(batch_size, int): batch_size = batch_size[0]
            td = self.generator(batch_size=batch_size).to(self.device)
            
        # ğŸ’¡ EnvëŠ” ì´ì œ ì´ˆê¸° í…ì„œë“¤ë§Œ ì œê³µí•©ë‹ˆë‹¤.
        #    ë‚˜ë¨¸ì§€ ìƒíƒœ(adj_matrix ë“±)ëŠ” ëª¨ë¸ì˜ forward íŒ¨ìŠ¤ì—ì„œ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.
        return td

    # ğŸ’¡ stepê³¼ get_action_maskëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì‚­ì œí•˜ê±°ë‚˜ ë¹„ì›Œë‘¡ë‹ˆë‹¤.
    def _step(self, td: TensorDict) -> TensorDict:
        # ì´ ë¡œì§ì€ ì´ì œ ëª¨ë¸ë¡œ ì´ì „ë˜ì—ˆìŠµë‹ˆë‹¤.
        raise NotImplementedError("Step logic has been moved to the model.")

    def get_reward(self, td: TensorDict) -> torch.Tensor:
        """
        ì—í”¼ì†Œë“œê°€ ì™„ë£Œë˜ì—ˆì„ ë•Œ ìµœì¢… ë³´ìƒì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        reward = torch.zeros(td.batch_size[0], device=self.device)
        done = td["done"].squeeze(-1)
        
        if done.any():
            is_used_mask = td["adj_matrix"][done].any(dim=1) | td["adj_matrix"][done].any(dim=2)
            node_costs = td["nodes"][done, :, FEATURE_INDEX["cost"]]
            ic_mask = td["nodes"][done, :, FEATURE_INDEX["node_type"][0] + NODE_TYPE_IC] == 1
            
            used_ic_mask = is_used_mask & ic_mask
            total_cost = (node_costs * used_ic_mask).sum(dim=-1)
            reward[done] = -total_cost
            
        return reward