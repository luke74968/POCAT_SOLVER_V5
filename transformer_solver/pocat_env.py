# transformer_solver/pocat_env.py
import torch
from tensordict import TensorDict
from torchrl.envs import EnvBase
from typing import Optional, Tuple
from torchrl.data import UnboundedContinuousTensorSpec as Unbounded, \
    UnboundedDiscreteTensorSpec as UnboundedDiscrete, \
    DiscreteTensorSpec as Categorical, \
    CompositeSpec as Composite

from common.pocat_defs import (
    NODE_TYPE_BATTERY, NODE_TYPE_IC, NODE_TYPE_LOAD,
    FEATURE_DIM, FEATURE_INDEX
)

class PocatEnv(EnvBase):
    name = "pocat"

    def __init__(self, generator_params: dict = {}, device: str = "cpu", **kwargs):
        super().__init__(device=device)
        from .pocat_generator import PocatGenerator
        self.generator = PocatGenerator(**generator_params)
        self._make_spec()
        self._set_seed(None)

    def _reset(self, td: Optional[TensorDict] = None, **kwargs) -> TensorDict:
        if td is None:
            batch_size = kwargs.get("batch_size", self.batch_size)
            if not isinstance(batch_size, int): batch_size = batch_size[0]
            td = self.generator(batch_size=batch_size).to(self.device)
            
        num_nodes = td["nodes"].shape[1]
        batch_size = td.batch_size[0]

        # --- ðŸ’¡ 1. ì œì•½ì¡°ê±´ ì¶”ì ì„ ìœ„í•œ ìƒíƒœ(state) í™•ìž¥ ---
        reset_td = TensorDict({
            "nodes": td["nodes"],
            "prompt_features": td["prompt_features"],
            # (B, N, N): i->j ì—°ê²° ì‹œ adj_matrix[:, i, j] = 1
            "adj_matrix": torch.zeros(batch_size, num_nodes, num_nodes, dtype=torch.bool, device=self.device),
            "connected_nodes_mask": torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device),
            "ic_current_draw": torch.zeros(batch_size, num_nodes, device=self.device),
            "step_count": torch.zeros(batch_size, 1, dtype=torch.long, device=self.device),
        }, batch_size=[batch_size], device=self.device)
        reset_td.set("done", torch.zeros(batch_size, 1, dtype=torch.bool, device=self.device))
        
        # ë°°í„°ë¦¬ ë…¸ë“œ(ì¸ë±ìŠ¤ 0)ëŠ” í•­ìƒ ì—°ê²°ëœ ìƒíƒœë¡œ ì‹œìž‘
        reset_td["connected_nodes_mask"][:, 0] = True
        return reset_td

    # ðŸ’¡ ì¶”ê°€ëœ step ë©”ì†Œë“œ: ë°°ì¹˜ í¬ê¸° ê²€ì‚¬ë¥¼ ìš°íšŒí•©ë‹ˆë‹¤.
    def step(self, tensordict: TensorDict) -> TensorDict:
        return self._step(tensordict)

    def _step(self, td: TensorDict) -> TensorDict:
        action = td["action"]
        child_idx, parent_idx = action[:, 0], action[:, 1]
        b_idx = torch.arange(td.batch_size[0], device=self.device)

        # ðŸ’¡ 2. í™•ìž¥ëœ ìƒíƒœ ì—…ë°ì´íŠ¸
        td["adj_matrix"][b_idx, parent_idx, child_idx] = True
        td["connected_nodes_mask"][b_idx, child_idx] = True
        
        # ì „ë¥˜ ì „íŒŒ ë¡œì§ (ê¸°ì¡´ê³¼ ìœ ì‚¬í•˜ë‚˜, ì¸ì ‘ í–‰ë ¬ ê¸°ë°˜ìœ¼ë¡œ ê°œì„  ê°€ëŠ¥)
        child_currents = td["nodes"][b_idx, child_idx, FEATURE_INDEX["current_active"]]
        for i in range(td.batch_size[0]):
            parent = parent_idx[i].item()
            increment = child_currents[i]
            # ë°°í„°ë¦¬ì— ë„ë‹¬í•  ë•Œê¹Œì§€ ìƒìœ„ë¡œ ì „ë¥˜ ì „íŒŒ
            while parent != 0:
                td["ic_current_draw"][i, parent] += increment
                ancestors = td["adj_matrix"][i, :, parent].nonzero(as_tuple=True)[0]
                if ancestors.numel() == 0: break
                parent = ancestors[0].item()

        load_indices = torch.where(td["nodes"][0, :, FEATURE_INDEX["node_type"][0] + NODE_TYPE_LOAD] == 1)[0]
        all_loads_connected = td["connected_nodes_mask"][:, load_indices].all(dim=1)
        
        next_obs = td.clone()
        next_obs.set("step_count", td["step_count"] + 1)
        
        return TensorDict({
            "next": next_obs,
            "reward": self.get_reward(td, all_loads_connected),
            "done": all_loads_connected.unsqueeze(-1),
        }, batch_size=td.batch_size)
    
    def get_action_mask(self, td: TensorDict) -> torch.Tensor:
        batch_size, num_nodes, _ = td["nodes"].shape
        
        # --- ê¸°ë³¸ ë§ˆìŠ¤í¬ (ì „ì••, ì „ë¥˜, ê¸°ë³¸ ì—°ê²° ê·œì¹™) ---
        node_types = td["nodes"][0, :, :FEATURE_INDEX["node_type"][1]].argmax(-1)
        is_load = node_types == NODE_TYPE_LOAD
        is_ic = node_types == NODE_TYPE_IC
        is_battery = node_types == NODE_TYPE_BATTERY
        
        can_be_child = ~td["connected_nodes_mask"] & (is_ic | is_load)
        can_be_parent = td["connected_nodes_mask"] & (is_ic | is_battery)
        
        base_mask = can_be_child.unsqueeze(1) & can_be_parent.unsqueeze(2)
        base_mask[:, torch.arange(num_nodes), torch.arange(num_nodes)] = False # ìžê¸° ìžì‹ ì—ê²Œ ì—°ê²° ê¸ˆì§€

        # ì „ì•• í˜¸í™˜ì„±
        parent_vout_max = td["nodes"][:, :, FEATURE_INDEX["vout_max"]].unsqueeze(2)
        child_vin_min = td["nodes"][:, :, FEATURE_INDEX["vin_min"]].unsqueeze(1)
        base_mask &= (parent_vout_max >= child_vin_min)

        # ì „ë¥˜ í•œê³„ (ì´ì œ ì—´ ë§ˆì§„ì´ ë°˜ì˜ëœ i_limit ì‚¬ìš©)
        child_currents = td["nodes"][:, :, FEATURE_INDEX["current_active"]].unsqueeze(1)
        prospective_draw = td["ic_current_draw"].unsqueeze(2) + child_currents
        parent_limits = td["nodes"][:, :, FEATURE_INDEX["i_limit"]].unsqueeze(2)
        # i_limit=0ì¸ ë…¸ë“œ(ë¶€í•˜, ë°°í„°ë¦¬)ëŠ” ë¬´í•œëŒ€ë¡œ ì²˜ë¦¬í•˜ì—¬ ì „ë¥˜ ê²€ì‚¬ í†µê³¼
        inf_limits = torch.where(parent_limits > 0, parent_limits, float("inf"))
        base_mask &= (prospective_draw.transpose(1, 2) <= inf_limits)

        # --- ðŸ’¡ 3. ë³µìž¡í•œ ì „ì—­ ì œì•½ì¡°ê±´ ë§ˆìŠ¤í‚¹ ---
        final_mask = base_mask
        
        # config.jsonì˜ ì œì•½ì¡°ê±´ íŒŒì‹±
        constraints = self.generator.config.constraints
        loads_info = self.generator.config.loads
        load_map = {l['name']: l for l in loads_info}
        node_names = self.generator.config.node_names
        
        # ì¡°ìƒ(ancestor) í–‰ë ¬ ê³„ì‚°: í”Œë¡œì´ë“œ-ì›Œì…œ ì•Œê³ ë¦¬ì¦˜ê³¼ ìœ ì‚¬
        ancestors = td["adj_matrix"].clone()
        for k in range(num_nodes):
            for i in range(num_nodes):
                for j in range(num_nodes):
                    ancestors[:, i, j] |= ancestors[:, i, k] & ancestors[:, k, j]

        # 1. ë…ë¦½ ë ˆì¼ (Independent Rail)
        for i, load in enumerate(loads_info):
            rail_type = load.get("independent_rail_type")
            if not rail_type: continue
            
            load_idx = self.generator.num_nodes - self.generator.num_loads + i
            
            if rail_type == 'exclusive_supplier':
                # ì´ ë¶€í•˜(load_idx)ë¥¼ ìžì‹ìœ¼ë¡œ ê°€ì§€ë ¤ëŠ” ë¶€ëª¨(p)ëŠ” ë‹¤ë¥¸ ìžì‹ì´ ìžˆìœ¼ë©´ ì•ˆ ë¨
                # ì¦‰, adj_matrix[p]ì˜ out-degreeê°€ 0ì´ì–´ì•¼ í•¨
                num_children = td["adj_matrix"].sum(dim=2) # (B, N)
                is_ok_parent = (num_children == 0)
                final_mask[:, :, load_idx] &= is_ok_parent

            elif rail_type == 'exclusive_path':
                # ì´ ë¶€í•˜ì˜ ì¡°ìƒë“¤ì€ ë‹¤ë¥¸ ìžì‹ì„ ê°€ì§ˆ ìˆ˜ ì—†ìŒ
                load_ancestors = ancestors[:, :, load_idx] # (B, N)
                num_children = td["adj_matrix"].sum(dim=2)
                # ì¡°ìƒì´ë©´ì„œ ìžì‹ì´ 1ê°œ ì´ˆê³¼ì¸ ë…¸ë“œ ì°¾ê¸° (ë°°í„°ë¦¬ ì œì™¸)
                violating_ancestors = load_ancestors & (num_children > 1) & is_ic.unsqueeze(0)
                # ìœ„ë°˜í•˜ëŠ” ì¡°ìƒì„ ë¶€ëª¨ë¡œ ì‚¼ìœ¼ë ¤ëŠ” ëª¨ë“  ì—°ê²°ì„ ê¸ˆì§€
                final_mask &= ~violating_ancestors.unsqueeze(2)

        # 2. ì „ì› ì¸ê°€ ìˆœì„œ (Power Sequence)
        for seq in constraints.get("power_sequences", []):
            j_name, k_name = seq['j'], seq['k']
            if j_name not in node_names or k_name not in node_names: continue
            j_idx, k_idx = node_names.index(j_name), node_names.index(k_name)

            # kì˜ ë¶€ëª¨(p)ëŠ” jì˜ ì¡°ìƒì´ ë  ìˆ˜ ì—†ìŒ
            j_ancestors = ancestors[:, :, j_idx] # (B, N)
            final_mask[:, :, k_idx] &= ~j_ancestors

            # jì™€ këŠ” ê°™ì€ ë¶€ëª¨ë¥¼ ê°€ì§ˆ ìˆ˜ ì—†ìŒ
            is_k_parent_mask = td["adj_matrix"][:, :, k_idx]  # (B, N) ëª¨ì–‘ì˜ ë¶ˆë¦¬ì–¸ ë§ˆìŠ¤í¬
            # final_maskì—ì„œ ìžì‹ì´ j_idxì¸ ìŠ¬ë¼ì´ìŠ¤ (B, N)ë¥¼ ì„ íƒí•œ ë’¤,
            # kì˜ ë¶€ëª¨ì¸ ìœ„ì¹˜ì— Falseë¥¼ ì ìš©í•©ë‹ˆë‹¤.
            final_mask[:, :, j_idx][is_k_parent_mask] = False

        return final_mask
    
    def get_reward(self, td: TensorDict, done: torch.Tensor) -> torch.Tensor:
        reward = torch.zeros(td.batch_size[0], device=self.device)
        if done.any():
            # ë¹„ìš© ê³„ì‚°
            node_costs = td["nodes"][done, :, FEATURE_INDEX["cost"]]
            ic_mask = td["nodes"][done, :, FEATURE_INDEX["node_type"][0] + NODE_TYPE_IC] == 1
            # is_used_mask: connected_nodes_maskì—ì„œ ë°°í„°ë¦¬ ì œì™¸
            is_used_mask = td["connected_nodes_mask"][done].clone()
            is_used_mask[:, 0] = False
            
            used_ic_mask = is_used_mask & ic_mask
            total_cost = (node_costs * used_ic_mask).sum(dim=-1)
            reward[done] = -total_cost
            
            # --- ðŸ’¡ 4. ìŠ¬ë¦½ ì „ë¥˜ ì œì•½ ìœ„ë°˜ ì‹œ íŽ˜ë„í‹° ---
            max_sleep_current = self.generator.config.constraints.get("max_sleep_current", 0.0)
            if max_sleep_current > 0:
                # (êµ¬í˜„ ê°„ì†Œí™”ë¥¼ ìœ„í•´ ê°„ë‹¨í•œ ë¡œì§ ì ìš©, ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ê³„ì‚° í•„ìš”)
                # Always-on ë¶€í•˜ë“¤ì˜ ìŠ¬ë¦½ ì „ë¥˜ í•©ê³„ë§Œìœ¼ë¡œ ê°„ë‹¨ížˆ ê³„ì‚°
                loads_info = self.generator.config.loads
                always_on_loads_current = sum(
                    l['current_sleep'] for l in loads_info if l.get('always_on_in_sleep')
                )
                # ì‹¤ì œë¡œëŠ” ICì˜ quiescent/operating currentë„ ì „íŒŒí•´ì•¼ í•¨
                if always_on_loads_current > max_sleep_current:
                    reward[done] -= 100.0 # í° íŽ˜ë„í‹°
                    
        return reward.unsqueeze(-1)
        
    def _make_spec(self):
        # ... (ê¸°ì¡´ê³¼ ë™ì¼, ë‹¨ instance_repeats ì œê±°) ...
        num_nodes = self.generator.num_nodes
        self.observation_spec = Composite({
            "nodes": Unbounded(shape=(num_nodes, FEATURE_DIM)),
            "prompt_features": Unbounded(shape=(2,)),
            "adj_matrix": Categorical(n=2, shape=(num_nodes, num_nodes), dtype=torch.bool),
            "connected_nodes_mask": Categorical(n=2, shape=(num_nodes,), dtype=torch.bool),
            "ic_current_draw": Unbounded(shape=(num_nodes,)),
            "step_count": UnboundedDiscrete(shape=(1,), dtype=torch.long),
        })
        self.action_spec = UnboundedDiscrete(shape=(2,), dtype=torch.long)
        self.reward_spec = Unbounded(shape=(1,))
        self.done_spec = Categorical(n=2, shape=(1,), dtype=torch.bool)

    def _set_seed(self, seed: Optional[int]):
        if seed is None:
            seed = torch.empty((), dtype=torch.int64).random_().item()
        rng = torch.manual_seed(seed)
        self.rng = rng

    def select_start_nodes(self, td: TensorDict) -> Tuple[int, torch.Tensor]:
        node_types = td["nodes"][0, :, :FEATURE_INDEX["node_type"][1]].argmax(-1)
        load_indices = torch.where(node_types == NODE_TYPE_LOAD)[0]
        num_starts = len(load_indices)
        start_nodes = load_indices.repeat_interleave(td.batch_size[0])
        return num_starts, start_nodes
