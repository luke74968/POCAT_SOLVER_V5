# transformer_solver/pocat_env.py
import torch
from tensordict import TensorDict
from torchrl.envs import EnvBase
from typing import Optional, Tuple
from torchrl.data import UnboundedContinuousTensorSpec as Unbounded, \
    UnboundedDiscreteTensorSpec as UnboundedDiscrete, \
    DiscreteTensorSpec as Categorical, \
    CompositeSpec as Composite

from common.pocat_defs import SCALAR_PROMPT_FEATURE_DIM

from common.pocat_defs import (
    NODE_TYPE_BATTERY, NODE_TYPE_IC, NODE_TYPE_LOAD,
    FEATURE_DIM, FEATURE_INDEX
)


class PocatEnv(EnvBase):
    name = "pocat"

    def __init__(self, generator_params: dict = {}, device: str = "cpu", **kwargs):
        super().__init__(device=device)
        from .pocat_generator import PocatGenerator
        self.generator = PocatGenerator(**generator_params)
        self._make_spec()
        self._set_seed(None) # ìƒì„±ìì—ì„œ í˜¸ì¶œì€ ë˜ì–´ ìˆìœ¼ë‚˜, ì•„ë˜ì— ë©”ì†Œë“œ ì •ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.

    # --- ğŸ‘‡ 1. ëˆ„ë½ëœ _make_spec ë©”ì†Œë“œ ì¶”ê°€ ---
    def _make_spec(self):
        """í™˜ê²½ì˜ observation, action, reward ìŠ¤í™ì„ ì •ì˜í•©ë‹ˆë‹¤."""
        num_nodes = self.generator.num_nodes
        
        # ê´€ì¸¡ ê³µê°„(Observation Space) ì •ì˜
        self.observation_spec = Composite({
            "nodes": Unbounded(
                shape=(num_nodes, FEATURE_DIM),
                dtype=torch.float32,
            ),
            # ğŸ’¡ ìˆ˜ì •: prompt_featuresë¥¼ ë‘ ì¢…ë¥˜ë¡œ ë‚˜ëˆ”
            "scalar_prompt_features": Unbounded(
                shape=(SCALAR_PROMPT_FEATURE_DIM,),
                dtype=torch.float32,
            ),
            "matrix_prompt_features": Unbounded(
                shape=(num_nodes, num_nodes),
                dtype=torch.float32,
            ),
            "adj_matrix": Unbounded(
                shape=(num_nodes, num_nodes),
                dtype=torch.bool,
            ),
            "main_tree_mask": Unbounded(
                shape=(num_nodes,),
                dtype=torch.bool,
            ),
            "ic_current_draw": Unbounded(
                shape=(num_nodes,),
                dtype=torch.float32,
            ),
            "decoding_phase": Categorical(
                shape=(1,),
                n=2, # 0: ìƒˆ Load ì„ íƒ, 1: Trajectory êµ¬ì¶•
                dtype=torch.long,
            ),
            "trajectory_head": UnboundedDiscrete(
                shape=(1,),
                dtype=torch.long,
            ),
            "unconnected_loads_mask": Unbounded(
                shape=(num_nodes,),
                dtype=torch.bool,
            ),
            "step_count": UnboundedDiscrete(
                shape=(1,),
                dtype=torch.long,
            ),
        })
        
        # í–‰ë™ ê³µê°„(Action Space) ì •ì˜: [ìì‹ ë…¸ë“œ, ë¶€ëª¨ ë…¸ë“œ]
        self.action_spec = UnboundedDiscrete(
            shape=(2,),
            dtype=torch.long,
        )
        
        # ë³´ìƒ(Reward) ìŠ¤í™ ì •ì˜
        self.reward_spec = Unbounded(shape=(1,))
        # ë³´ìƒ(Reward) ìŠ¤í™ ì •ì˜
        self.reward_spec = Unbounded(shape=(1,))

    # --- ğŸ‘‡ 2. ëˆ„ë½ëœ _set_seed ë©”ì†Œë“œ ì¶”ê°€ ---
    def _set_seed(self, seed: Optional[int] = None):
        """í™˜ê²½ì˜ ëœë¤ ì‹œë“œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. (torchrl í•„ìˆ˜ êµ¬í˜„)"""
        # í˜„ì¬ í™˜ê²½ì€ ìì²´ì ì¸ ëœë¤ ìš”ì†Œê°€ ì—†ìœ¼ë¯€ë¡œ íŠ¹ë³„í•œ ë¡œì§ì€ í•„ìš” ì—†ìŠµë‹ˆë‹¤.
        # í•˜ì§€ë§Œ EnvBaseë¥¼ ìƒì†ë°›ê¸° ìœ„í•´ ë°˜ë“œì‹œ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.
        if seed is not None:
            torch.manual_seed(seed)

    # --- ğŸ‘‡ 1. ëˆ„ë½ë˜ì—ˆë˜ select_start_nodes ë©”ì†Œë“œ ì¶”ê°€ ---
    def select_start_nodes(self, td: TensorDict) -> Tuple[int, torch.Tensor]:
        """POMO decodingì„ ìœ„í•´ ì‹œì‘ ë…¸ë“œ(ëª¨ë“  Load)ë¥¼ ì„ íƒí•©ë‹ˆë‹¤."""
        # ë…¸ë“œ íƒ€ì… ì •ë³´ëŠ” ë°°ì¹˜ ë‚´ì—ì„œ ë™ì¼í•˜ë¯€ë¡œ 0ë²ˆ ì¸ë±ìŠ¤ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        node_types = td["nodes"][0, :, :FEATURE_INDEX["node_type"][1]].argmax(-1)
        start_nodes_idx = torch.where(node_types == NODE_TYPE_LOAD)[0]
        num_starts = len(start_nodes_idx)
        return num_starts, start_nodes_idx

    # --- ğŸ‘‡ 2. ëˆ„ë½ë˜ì—ˆë˜ ê²½ë¡œ ì¶”ì  í—¬í¼ ë©”ì†Œë“œë“¤ ì¶”ê°€ ---
    def _trace_path(self, b_idx: int, start_node: int, adj_matrix: torch.Tensor) -> list[int]:
        """ë‹¨ì¼ ë°°ì¹˜ í•­ëª©ì— ëŒ€í•´ start_nodeì—ì„œ ì‹œì‘í•˜ëŠ” ê²½ë¡œë¥¼ ì—­ì¶”ì í•˜ì—¬ ë…¸ë“œ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        path = [start_node]
        current_node = start_node
        # adj_matrix[b_idx, parent, child] í˜•íƒœì´ë¯€ë¡œ, current_nodeë¥¼ ìì‹ìœ¼ë¡œ ê°–ëŠ” ë¶€ëª¨ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        while True:
            parents = adj_matrix[b_idx, :, current_node].nonzero(as_tuple=True)[0]
            if parents.numel() == 0:
                break
            parent_node = parents[0].item() # ê²½ë¡œëŠ” í•˜ë‚˜ë¿ì´ë¼ê³  ê°€ì •
            path.append(parent_node)
            current_node = parent_node
        return path

    def _trace_path_batch(self, b_idx: torch.Tensor, start_nodes: torch.Tensor, adj_matrix: torch.Tensor) -> torch.Tensor:
        """ë°°ì¹˜ ì „ì²´ì— ëŒ€í•´ start_nodeë“¤ì˜ ëª¨ë“  ì¡°ìƒì„ ì°¾ì•„ ë§ˆìŠ¤í¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        num_nodes = adj_matrix.shape[-1]
        
        # ì„ íƒëœ ë°°ì¹˜ í•­ëª©ë“¤ì— ëŒ€í•œ ì¸ì ‘ í–‰ë ¬
        adj_b = adj_matrix[b_idx]
        
        # ê²½ë¡œ ë§ˆìŠ¤í¬ ì´ˆê¸°í™” (ì‹œì‘ ë…¸ë“œë§Œ True)
        path_mask = torch.zeros(len(b_idx), num_nodes, dtype=torch.bool, device=self.device)
        path_mask[torch.arange(len(b_idx)), start_nodes] = True
        
        # í–‰ë ¬ ê³±ì…ˆì„ ì´ìš©í•´ ê·¸ë˜í”„ë¥¼ ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°€ë©° ëª¨ë“  ì¡°ìƒì„ ì°¾ìŠµë‹ˆë‹¤.
        for _ in range(num_nodes):
            # í˜„ì¬ ê²½ë¡œì— í¬í•¨ëœ ë…¸ë“œë“¤ì˜ ë¶€ëª¨ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            parents_mask = (adj_b.float() @ path_mask.float().unsqueeze(-1)).squeeze(-1) > 0
            
            # ë” ì´ìƒ ìƒˆë¡œìš´ ë¶€ëª¨ê°€ ì—†ìœ¼ë©´ (ê²½ë¡œì˜ ëì— ë„ë‹¬í•˜ë©´) ì¢…ë£Œí•©ë‹ˆë‹¤.
            if (parents_mask & ~path_mask).sum() == 0:
                break
            
            # ìƒˆë¡œ ì°¾ì€ ë¶€ëª¨ë“¤ì„ ê²½ë¡œ ë§ˆìŠ¤í¬ì— ì¶”ê°€í•©ë‹ˆë‹¤.
            path_mask |= parents_mask
            
        return path_mask            

    def _reset(self, td: Optional[TensorDict] = None, **kwargs) -> TensorDict:
        if td is None:
            batch_size = kwargs.get("batch_size", self.batch_size)
            if not isinstance(batch_size, int): batch_size = batch_size[0]
            td = self.generator(batch_size=batch_size).to(self.device)
            
        num_nodes = td["nodes"].shape[1]
        batch_size = td.batch_size[0]
        
        # --- ğŸ’¡ 1. Trajectory ê¸°ë°˜ ìƒíƒœ(state) ì¬ì •ì˜ ---
        reset_td = TensorDict({
            "nodes": td["nodes"],
            "scalar_prompt_features": td["scalar_prompt_features"],
            "matrix_prompt_features": td["matrix_prompt_features"],
            "adj_matrix": torch.zeros(batch_size, num_nodes, num_nodes, dtype=torch.bool, device=self.device),
            "main_tree_mask": torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device),
            "ic_current_draw": torch.zeros(batch_size, num_nodes, device=self.device),
            
            # --- ìƒˆë¡œìš´ ìƒíƒœ ë³€ìˆ˜ ---
            # 0: ìƒˆ Load ì„ íƒ ë‹¨ê³„, 1: Trajectory(ê²½ë¡œ) êµ¬ì¶• ë‹¨ê³„
            "decoding_phase": torch.zeros(batch_size, 1, dtype=torch.long, device=self.device),
            # í˜„ì¬ ë§Œë“¤ê³  ìˆëŠ” ê²½ë¡œì˜ ê°€ì¥ ë ë…¸ë“œ (Loadì—ì„œ ë°°í„°ë¦¬ ë°©í–¥ìœ¼ë¡œ)
            "trajectory_head": torch.full((batch_size, 1), -1, dtype=torch.long, device=self.device),
            # ì•„ì§ íŠ¸ë¦¬ì— ì—°ê²°ë˜ì§€ ì•Šì€ Loadë“¤ì˜ ë§ˆìŠ¤í¬
            "unconnected_loads_mask": torch.ones(batch_size, num_nodes, dtype=torch.bool, device=self.device),
            
            "step_count": torch.zeros(batch_size, 1, dtype=torch.long, device=self.device),
        }, batch_size=[batch_size], device=self.device)
        
        reset_td.set("done", torch.zeros(batch_size, 1, dtype=torch.bool, device=self.device))
        
        # ë°°í„°ë¦¬(ì¸ë±ìŠ¤ 0)ëŠ” í•­ìƒ ë©”ì¸ íŠ¸ë¦¬ì— í¬í•¨
        reset_td["main_tree_mask"][:, 0] = True
        
        node_types = td["nodes"][0, :, :FEATURE_INDEX["node_type"][1]].argmax(-1)
        is_load = node_types == NODE_TYPE_LOAD
        reset_td["unconnected_loads_mask"][:, ~is_load] = False
        
        return reset_td

    # ğŸ’¡ ì¶”ê°€ëœ step ë©”ì†Œë“œ: ë°°ì¹˜ í¬ê¸° ê²€ì‚¬ë¥¼ ìš°íšŒí•©ë‹ˆë‹¤.
    def step(self, tensordict: TensorDict) -> TensorDict:
        return self._step(tensordict)

    def _step(self, td: TensorDict) -> TensorDict:
        action = td["action"]
        b_idx = torch.arange(td.batch_size[0], device=self.device)
        phase = td["decoding_phase"].squeeze(-1)

        next_obs = td.clone()

        phase0_mask = phase == 0
        phase1_mask = phase == 1
        b_phase0 = b_idx[phase0_mask]
        b_phase1 = b_idx[phase1_mask]

        if b_phase0.numel() > 0:  # ìƒˆ Load ì„ íƒ ë‹¨ê³„
            selected_load = action[b_phase0, 0]
            next_obs["trajectory_head"][b_phase0] = selected_load.unsqueeze(-1)
            next_obs["unconnected_loads_mask"][b_phase0, selected_load] = False
            next_obs["decoding_phase"][b_phase0, 0] = 1  # ë‹¤ìŒì€ ê²½ë¡œ êµ¬ì¶• ë‹¨ê³„ë¡œ

        if b_phase1.numel() > 0:  # Trajectory êµ¬ì¶• ë‹¨ê³„
            child_idx, parent_idx = action[b_phase1, 0], action[b_phase1, 1]
            next_obs["adj_matrix"][b_phase1, parent_idx, child_idx] = True
            #assert parent_idx.shape == child_idx.shape == b_phase1.shape, \
            #"shape mismatch in (b, parent, child) triplets"


            # [ìˆ˜ì •] ì „ë¥˜ ì „íŒŒ ë¡œì§ êµ¬í˜„
            path_nodes_mask = self._trace_path_batch(b_phase1, child_idx, next_obs["adj_matrix"])
            path_nodes_currents = (
                td["nodes"][b_phase1] * path_nodes_mask.unsqueeze(-1)
            )[:, :, FEATURE_INDEX["current_active"]]

            for idx, b in enumerate(b_phase1.tolist()):
                total_child_current = path_nodes_currents[idx].sum()
                ancestor = parent_idx[idx].item()
                while ancestor != 0:
                    next_obs["ic_current_draw"][b, ancestor] += total_child_current
                    ancestors_of_ancestor = next_obs["adj_matrix"][b, :, ancestor].nonzero(as_tuple=True)[0]
                    if ancestors_of_ancestor.numel() == 0:
                        break
                    ancestor = ancestors_of_ancestor[0].item()

            is_parent_in_main_tree = next_obs["main_tree_mask"][b_phase1, parent_idx]

            for idx, b in enumerate(b_phase1.tolist()):
                if is_parent_in_main_tree[idx]:
                    path_nodes_indices = self._trace_path(b, child_idx[idx], next_obs["adj_matrix"])
                    next_obs["main_tree_mask"][b, path_nodes_indices] = True
                    if next_obs["unconnected_loads_mask"][b].sum() == 0:
                        next_obs["done"][b] = True
                    else:
                        next_obs["decoding_phase"][b] = 0
                else:
                    next_obs["trajectory_head"][b] = parent_idx[idx]

        next_obs.set("step_count", td["step_count"] + 1)
        
        return TensorDict({
            "next": next_obs,
            "reward": self.get_reward(next_obs),
            "done": next_obs["done"],
        }, batch_size=td.batch_size)
    
    def get_action_mask(self, td: TensorDict) -> torch.Tensor:
        batch_size, num_nodes, _ = td["nodes"].shape
        mask = torch.zeros(batch_size, num_nodes, num_nodes, dtype=torch.bool, device=self.device)

        # Phase 0: ì•„ì§ ì—°ê²°ë˜ì§€ ì•Šì€ Loadë§Œ ì„ íƒ ê°€ëŠ¥
        phase0_mask = (td["decoding_phase"].squeeze(-1) == 0)
        if phase0_mask.any():
            mask[phase0_mask, :, 0] = td["unconnected_loads_mask"][phase0_mask]

#        if phase1_idx.numel() > 0:
#            b_idx = phase1_idx

        # Phase 1: í˜„ì¬ ê²½ë¡œë¥¼ ì´ì„ ë¶€ëª¨ ë…¸ë“œ ì„ íƒ
        phase1_mask = ~phase0_mask
        if phase1_mask.any():
            b_idx = torch.where(phase1_mask)[0]
            child_indices = td["trajectory_head"][b_idx].squeeze(-1)

            can_be_parent = torch.ones(len(b_idx), num_nodes, dtype=torch.bool, device=self.device)
            node_types = td["nodes"][0, :, :FEATURE_INDEX["node_type"][1]].argmax(-1)
            
                # ğŸ’¡ [í•µì‹¬ ìˆ˜ì •] ëª…í™•í•œ ë‹¨ê³„ì  í•„í„°ë§ìœ¼ë¡œ ë¡œì§ ë³€ê²½
            # 1. ë¶€í•˜ëŠ” ë¶€ëª¨ê°€ ë  ìˆ˜ ì—†ìŒ
            is_load = (node_types == NODE_TYPE_LOAD)
            can_be_parent &= ~is_load.unsqueeze(0)

            # 2. í˜„ì¬ ë§Œë“¤ê³  ìˆëŠ” ê²½ë¡œì— í¬í•¨ëœ ë…¸ë“œëŠ” ë¶€ëª¨ê°€ ë  ìˆ˜ ì—†ìŒ (ì‚¬ì´í´ ë°©ì§€)
            current_path_mask = self._trace_path_batch(b_idx, child_indices, td["adj_matrix"])
            can_be_parent &= ~current_path_mask


            # ğŸ’¡ [í•µì‹¬ ìˆ˜ì •] ì „ì•• í˜¸í™˜ì„± ê²€ì‚¬ ë¡œì§ì„ 'ë²”ìœ„' ê¸°ë°˜ìœ¼ë¡œ ì˜¬ë°”ë¥´ê²Œ ìˆ˜ì •
            child_vin_min = td["nodes"][b_idx, child_indices, FEATURE_INDEX["vin_min"]]
            child_vin_max = td["nodes"][b_idx, child_indices, FEATURE_INDEX["vin_max"]]
            
            parent_vout_min = td["nodes"][b_idx, :, FEATURE_INDEX["vout_min"]]
            parent_vout_max = td["nodes"][b_idx, :, FEATURE_INDEX["vout_max"]]

            # ì¡°ê±´: ë¶€ëª¨ì˜ ì¶œë ¥ ì „ì•• ë²”ìœ„ì™€ ìì‹ì˜ ì…ë ¥ ì „ì•• ë²”ìœ„ê°€ ê²¹ì³ì•¼ í•¨
            # (parent_min <= child_max) AND (parent_max >= child_min)
            is_voltage_compatible = (parent_vout_min <= child_vin_max.unsqueeze(1)) & \
                                    (parent_vout_max >= child_vin_min.unsqueeze(1))
            can_be_parent &= is_voltage_compatible

            # 2. ì „ë¥˜ í•œê³„
            path_nodes_currents = (td["nodes"][b_idx, :, FEATURE_INDEX["current_active"]] * current_path_mask).sum(dim=1)
            prospective_draw = td["ic_current_draw"][b_idx] + path_nodes_currents.unsqueeze(1)
            parent_limits = td["nodes"][b_idx, :, FEATURE_INDEX["i_limit"]]
            # ë°°í„°ë¦¬(i_limit=0)ëŠ” ì „ë¥˜ í•œê³„ê°€ ì—†ë‹¤ê³  ê°€ì •
            can_be_parent &= (prospective_draw <= parent_limits) | (parent_limits == 0) 

            
            # 3. ê¸°íƒ€ ì œì•½ì¡°ê±´
            # (ì´í•˜ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€)
            constraints, loads_info, node_names = self.generator.config.constraints, self.generator.config.loads, self.generator.config.node_names
            ancestors = td["adj_matrix"][b_idx].clone()
            for k in range(num_nodes):
                for i in range(num_nodes):
                    for j in range(num_nodes):
                        ancestors[:, i, j] |= ancestors[:, i, k] & ancestors[:, k, j]
            
            head_load_idx = child_indices - (1 + len(self.generator.config.available_ics))
            for idx, b in enumerate(b_idx.tolist()):
                if 0 <= head_load_idx[idx] < len(loads_info):
                    load = loads_info[head_load_idx[idx]]
                    rail_type = load.get("independent_rail_type")
                    if rail_type == "exclusive_supplier": can_be_parent[idx] &= td["adj_matrix"][b].sum(dim=1) == 0
                    elif rail_type == "exclusive_path": can_be_parent[idx] &= td["adj_matrix"][b].sum(dim=1) <= 1
            
            for seq in constraints.get("power_sequences", []):
                if seq.get("f") != 1: continue
                j_name, k_name = seq.get("j"), seq.get("k")
                if j_name not in node_names or k_name not in node_names: continue
                j_idx, k_idx = node_names.index(j_name), node_names.index(k_name)
                is_head_k_mask = child_indices == k_idx
                if is_head_k_mask.any():
                    can_be_parent[is_head_k_mask] &= ~ancestors[is_head_k_mask, :, j_idx]
            
            mask[b_idx, :, child_indices] = can_be_parent
        return mask

    
    def get_reward(self, td: TensorDict) -> torch.Tensor:
        """
        Calculates the reward based on the final state of the power tree.
        The reward is the negative of the total cost of used ICs.
        This function is called only when an episode is done.
        """
        reward = torch.zeros(td.batch_size[0], device=self.device)
        done = td["done"].squeeze(-1)
        
        if done.any():
            # Calculate cost based on the final adjacency matrix
            is_used_mask = td["adj_matrix"][done].any(dim=1) | td["adj_matrix"][done].any(dim=2)
            
            node_costs = td["nodes"][done, :, FEATURE_INDEX["cost"]]
            ic_mask = td["nodes"][done, :, FEATURE_INDEX["node_type"][0] + NODE_TYPE_IC] == 1
            
            used_ic_mask = is_used_mask & ic_mask
            total_cost = (node_costs * used_ic_mask).sum(dim=-1)
            reward[done] = -total_cost
            
            # (Optional) Add penalty for violating sleep current constraint
            max_sleep_current = self.generator.config.constraints.get("max_sleep_current", 0.0)
            if max_sleep_current > 0:
                loads_info = self.generator.config.loads
        return reward