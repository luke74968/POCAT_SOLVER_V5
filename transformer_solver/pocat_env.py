# transformer_solver/pocat_env.py
import torch
from tensordict import TensorDict
from torchrl.envs import EnvBase
from typing import Optional, Tuple
from torchrl.data import UnboundedContinuousTensorSpec as Unbounded, \
    UnboundedDiscreteTensorSpec as UnboundedDiscrete, \
    DiscreteTensorSpec as Categorical, \
    CompositeSpec as Composite

from common.pocat_defs import SCALAR_PROMPT_FEATURE_DIM

from common.pocat_defs import (
    NODE_TYPE_BATTERY, NODE_TYPE_IC, NODE_TYPE_LOAD,
    FEATURE_DIM, FEATURE_INDEX
)


class PocatEnv(EnvBase):
    name = "pocat"

    def __init__(self, generator_params: dict = {}, device: str = "cpu", **kwargs):
        super().__init__(device=device)
        from .pocat_generator import PocatGenerator
        self.generator = PocatGenerator(**generator_params)
        self._make_spec()
        self._set_seed(None) # ìƒì„±ìì—ì„œ í˜¸ì¶œì€ ë˜ì–´ ìˆìœ¼ë‚˜, ì•„ë˜ì— ë©”ì†Œë“œ ì •ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.

    def _make_spec(self):
        """í™˜ê²½ì˜ observation, action, reward ìŠ¤í™ì„ ì •ì˜í•©ë‹ˆë‹¤."""
        num_nodes = self.generator.num_nodes
        
        self.observation_spec = Composite({
            "nodes": Unbounded(shape=(num_nodes, FEATURE_DIM), dtype=torch.float32),
            "scalar_prompt_features": Unbounded(shape=(SCALAR_PROMPT_FEATURE_DIM,), dtype=torch.float32),
            "matrix_prompt_features": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.float32),
            "adj_matrix": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.bool),
            "main_tree_mask": Unbounded(shape=(num_nodes,), dtype=torch.bool),
            "ic_current_draw": Unbounded(shape=(num_nodes,), dtype=torch.float32),
            "decoding_phase": Categorical(shape=(1,), n=2, dtype=torch.long),
            "trajectory_head": UnboundedDiscrete(shape=(1,), dtype=torch.long),
            "unconnected_loads_mask": Unbounded(shape=(num_nodes,), dtype=torch.bool),
            "step_count": UnboundedDiscrete(shape=(1,), dtype=torch.long),
        })
        
        self.action_spec = UnboundedDiscrete(shape=(2,), dtype=torch.long)
        self.reward_spec = Unbounded(shape=(1,))

    def _set_seed(self, seed: Optional[int] = None):
        if seed is not None:
            torch.manual_seed(seed)

    def select_start_nodes(self, td: TensorDict) -> Tuple[int, torch.Tensor]:
        node_types = td["nodes"][0, :, :FEATURE_INDEX["node_type"][1]].argmax(-1)
        start_nodes_idx = torch.where(node_types == NODE_TYPE_LOAD)[0]
        return len(start_nodes_idx), start_nodes_idx
    
    def _trace_path_batch(self, b_idx: torch.Tensor, start_nodes: torch.Tensor, adj_matrix: torch.Tensor) -> torch.Tensor:
        """ë°°ì¹˜ ì „ì²´ì— ëŒ€í•´ start_nodeë“¤ì˜ ëª¨ë“  ì¡°ìƒì„ ì°¾ì•„ ë§ˆìŠ¤í¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        # b_idxëŠ” ì´ì œ ì‹¤ì œ í…ì„œì˜ í¬ê¸°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ arangeê°€ ë  ê²ƒì…ë‹ˆë‹¤.
        num_nodes = adj_matrix.shape[-1]
        adj_b = adj_matrix # ì´ë¯¸ sub-batchì´ë¯€ë¡œ ì¸ë±ì‹± ë¶ˆí•„ìš”
        path_mask = torch.zeros(len(b_idx), num_nodes, dtype=torch.bool, device=self.device)
        path_mask[b_idx, start_nodes] = True # b_idxë¥¼ arangeë¡œ ì‚¬ìš©
        
        # í–‰ë ¬ ê³±ì…ˆì„ ì´ìš©í•´ ê·¸ë˜í”„ë¥¼ ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°€ë©° ëª¨ë“  ì¡°ìƒì„ ì°¾ìŠµë‹ˆë‹¤.
        for _ in range(num_nodes):
            # í˜„ì¬ ê²½ë¡œì— í¬í•¨ëœ ë…¸ë“œë“¤ì˜ ë¶€ëª¨ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            parents_mask = (adj_b.float() @ path_mask.float().unsqueeze(-1)).squeeze(-1) > 0
            
            # ë” ì´ìƒ ìƒˆë¡œìš´ ë¶€ëª¨ê°€ ì—†ìœ¼ë©´ (ê²½ë¡œì˜ ëì— ë„ë‹¬í•˜ë©´) ì¢…ë£Œí•©ë‹ˆë‹¤.
            if (parents_mask & ~path_mask).sum() == 0:
                break
            
            # ìƒˆë¡œ ì°¾ì€ ë¶€ëª¨ë“¤ì„ ê²½ë¡œ ë§ˆìŠ¤í¬ì— ì¶”ê°€í•©ë‹ˆë‹¤.
            path_mask |= parents_mask
            
        return path_mask            

    def _reset(self, td: Optional[TensorDict] = None, **kwargs) -> TensorDict:
        if td is None:
            batch_size = kwargs.get("batch_size", self.batch_size)
            if not isinstance(batch_size, int): batch_size = batch_size[0]
            td = self.generator(batch_size=batch_size).to(self.device)
            
        num_nodes = td["nodes"].shape[1]
        batch_size = td.batch_size[0]
        
        # --- ğŸ’¡ 1. Trajectory ê¸°ë°˜ ìƒíƒœ(state) ì¬ì •ì˜ ---
        reset_td = TensorDict({
            "nodes": td["nodes"],
            "scalar_prompt_features": td["scalar_prompt_features"],
            "matrix_prompt_features": td["matrix_prompt_features"],
            "adj_matrix": torch.zeros(batch_size, num_nodes, num_nodes, dtype=torch.bool, device=self.device),
            "main_tree_mask": torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device),
            "ic_current_draw": torch.zeros(batch_size, num_nodes, device=self.device),
            
            # --- ìƒˆë¡œìš´ ìƒíƒœ ë³€ìˆ˜ ---
            # 0: ìƒˆ Load ì„ íƒ ë‹¨ê³„, 1: Trajectory(ê²½ë¡œ) êµ¬ì¶• ë‹¨ê³„
            "decoding_phase": torch.zeros(batch_size, 1, dtype=torch.long, device=self.device),
            # í˜„ì¬ ë§Œë“¤ê³  ìˆëŠ” ê²½ë¡œì˜ ê°€ì¥ ë ë…¸ë“œ (Loadì—ì„œ ë°°í„°ë¦¬ ë°©í–¥ìœ¼ë¡œ)
            "trajectory_head": torch.full((batch_size, 1), -1, dtype=torch.long, device=self.device),
            # ì•„ì§ íŠ¸ë¦¬ì— ì—°ê²°ë˜ì§€ ì•Šì€ Loadë“¤ì˜ ë§ˆìŠ¤í¬
            "unconnected_loads_mask": torch.ones(batch_size, num_nodes, dtype=torch.bool, device=self.device),
            
            "step_count": torch.zeros(batch_size, 1, dtype=torch.long, device=self.device),
        }, batch_size=[batch_size], device=self.device)
        
        reset_td.set("done", torch.zeros(batch_size, 1, dtype=torch.bool, device=self.device))
        
        # ë°°í„°ë¦¬(ì¸ë±ìŠ¤ 0)ëŠ” í•­ìƒ ë©”ì¸ íŠ¸ë¦¬ì— í¬í•¨
        reset_td["main_tree_mask"][:, 0] = True
        
        node_types = td["nodes"][0, :, :FEATURE_INDEX["node_type"][1]].argmax(-1)
        is_load = node_types == NODE_TYPE_LOAD
        reset_td["unconnected_loads_mask"][:, ~is_load] = False
        
        return reset_td

    # ğŸ’¡ ì¶”ê°€ëœ step ë©”ì†Œë“œ: ë°°ì¹˜ í¬ê¸° ê²€ì‚¬ë¥¼ ìš°íšŒí•©ë‹ˆë‹¤.
    def step(self, tensordict: TensorDict) -> TensorDict:
        return self._step(tensordict)

    def _step(self, td: TensorDict) -> TensorDict:
        action = td["action"]
        b_idx = torch.arange(td.batch_size[0], device=self.device)
        phase = td["decoding_phase"].squeeze(-1)
        next_obs = td.clone()

        # <<<ìˆ˜ì •>>>: ëª…ì‹œì  ëŒ€ê¸°(wait) ì•¡ì…˜ [0, 0]ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        wait_action_mask = (action[:, 0] == 0) & (action[:, 1] == 0)
        # ëŒ€ê¸° ì•¡ì…˜ì„ ìˆ˜í–‰í•œ íƒìƒ‰ì€ ì•„ë¬´ ìƒíƒœ ë³€í™” ì—†ì´ ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.
        # ì´ ì•¡ì…˜ì€ ì˜¤ì§ ëª¨ë“  Loadë¥¼ ì—°ê²°í•œ íƒìƒ‰ì—ê²Œë§Œ í—ˆìš©ë©ë‹ˆë‹¤.
        if wait_action_mask.any():
            pass
                
        # Phase 0: ìƒˆ Load ì„ íƒ
        phase0_mask = (phase == 0) & ~wait_action_mask
        if phase0_mask.any():
            b_phase0 = b_idx[phase0_mask]
            selected_load = action[b_phase0, 0]
            next_obs["trajectory_head"][b_phase0] = selected_load.unsqueeze(-1)
            next_obs["unconnected_loads_mask"][b_phase0, selected_load] = False
            next_obs["decoding_phase"][b_phase0] = 1

        # Phase 1: Trajectory(ê²½ë¡œ) êµ¬ì¶•
        phase1_mask = (phase == 1) & ~wait_action_mask
        if phase1_mask.any():
            # << ìˆ˜ì •: Phase 1ì—ì„œë§Œ ì‚¬ìš©ë˜ëŠ” ëª¨ë“  ë³€ìˆ˜ì™€ ë¡œì§ì„ ì´ ë¸”ë¡ ì•ˆìœ¼ë¡œ ì´ë™ >>
            b_phase1 = b_idx[phase1_mask]
            child_idx, parent_idx = action[b_phase1, 0], action[b_phase1, 1]
            next_obs["adj_matrix"][b_phase1, parent_idx, child_idx] = True

            path_nodes_mask = self._trace_path_batch(torch.arange(len(b_phase1)), child_idx, next_obs["adj_matrix"][b_phase1])
            path_nodes_currents = (td["nodes"][b_phase1] * path_nodes_mask.unsqueeze(-1))[:, :, FEATURE_INDEX["current_active"]]
            total_child_currents = path_nodes_currents.sum(dim=1)

            ancestor_mask = self._trace_path_batch(torch.arange(len(b_phase1)), parent_idx, next_obs["adj_matrix"][b_phase1])
            battery_mask = torch.zeros_like(ancestor_mask); battery_mask[:, 0] = True
            ancestor_mask_no_battery = ancestor_mask & ~battery_mask

            
            current_draw_update = ancestor_mask_no_battery.float().transpose(-1, -2) @ total_child_currents.float().unsqueeze(-1)
            next_obs["ic_current_draw"][b_phase1] += current_draw_update.squeeze(-1)

            is_parent_in_main_tree = next_obs["main_tree_mask"][b_phase1, parent_idx]
            
            b_connected = b_phase1[is_parent_in_main_tree]
            if b_connected.numel() > 0:
                child_connected = child_idx[is_parent_in_main_tree]
                newly_connected_path_mask = self._trace_path_batch(torch.arange(len(b_connected)), child_connected, next_obs["adj_matrix"][b_connected])
                next_obs["main_tree_mask"][b_connected] |= newly_connected_path_mask
                next_obs["decoding_phase"][b_connected] = 0

            b_not_connected = b_phase1[~is_parent_in_main_tree]
            if b_not_connected.numel() > 0:
                parent_not_connected = parent_idx[~is_parent_in_main_tree]
                next_obs["trajectory_head"][b_not_connected] = parent_not_connected.unsqueeze(-1)
        
        next_obs.set("step_count", td["step_count"] + 1)

        # ğŸ’¡ *** ì—¬ê¸°ê°€ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ì…ë‹ˆë‹¤ (1/2) ***
        # 1. ëª¨ë“  ë¶€í•˜ê°€ ì—°ê²°ë˜ì—ˆëŠ”ì§€ í™•ì¸
        all_loads_connected = (next_obs["unconnected_loads_mask"].sum(dim=1) == 0)
        # 2. í˜„ì¬ ìƒˆë¡œìš´ ê²½ë¡œë¥¼ ë§Œë“¤ê³  ìˆì§€ ì•Šì€ì§€ í™•ì¸ (ëª¨ë“  ê²½ë¡œê°€ ì£¼ ì „ë ¥ë§ì— ì—°ê²°ë˜ì—ˆëŠ”ì§€)
        in_selection_phase = (next_obs["decoding_phase"].squeeze(-1) == 0)
        # 3. ë‘ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•´ì•¼ ì„±ê³µì ìœ¼ë¡œ ì¢…ë£Œ
        done_successfully = all_loads_connected & in_selection_phase
        
        # 4. íƒ€ì„ì•„ì›ƒ(ì•ˆì „ë§) í™•ì¸
        max_steps = 2 * self.generator.num_nodes
        timed_out = (next_obs["step_count"] > max_steps).squeeze(-1)
        
        is_done = done_successfully | timed_out
        next_obs["done"] = is_done.unsqueeze(-1)
        
        return TensorDict({
            "next": next_obs,
            "reward": self.get_reward(next_obs, timed_out),
            "done": next_obs["done"],
        }, batch_size=td.batch_size)
        
    # ğŸ’¡ *** ì—¬ê¸°ê°€ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ì…ë‹ˆë‹¤ ***
    def get_action_mask(self, td: TensorDict) -> torch.Tensor:
        batch_size, num_nodes, _ = td["nodes"].shape
        mask = torch.zeros(batch_size, num_nodes, num_nodes, dtype=torch.bool, device=self.device)

        # <<<ìˆ˜ì •>>>: "ëŒ€ê¸°" ìƒíƒœì™€ "ì§„í–‰" ìƒíƒœë¥¼ ëª…í™•íˆ ë¶„ë¦¬í•©ë‹ˆë‹¤.
        # 1. ëª¨ë“  Loadë¥¼ ì—°ê²°í•œ íƒìƒ‰(finished rollouts)ì„ ì°¾ìŠµë‹ˆë‹¤.
        all_loads_connected = (td["unconnected_loads_mask"].sum(dim=1) == 0)

        # 2. ì´ "ëë‚œ" íƒìƒ‰ë“¤ì—ê²ŒëŠ” ëª…ì‹œì ì¸ "ëŒ€ê¸°(wait)" ì•¡ì…˜ [0, 0]ë§Œ í—ˆìš©í•©ë‹ˆë‹¤.
        if all_loads_connected.any():
            mask[all_loads_connected, 0, 0] = True

        # 3. ì•„ì§ ëë‚˜ì§€ ì•Šì€ íƒìƒ‰(unfinished rollouts)ì„ ì°¾ìŠµë‹ˆë‹¤.
        unfinished_mask = ~all_loads_connected

        # 4. ëë‚˜ì§€ ì•Šì€ íƒìƒ‰ì´ ì—†ë‹¤ë©´, ì—¬ê¸°ì„œ ë§ˆìŠ¤í¬ ë°˜í™˜ (ëª¨ë‘ ëŒ€ê¸° ìƒíƒœ)
        if not unfinished_mask.any():
            return mask
        
        # 5. ëë‚˜ì§€ ì•Šì€ íƒìƒ‰ì— ëŒ€í•´ì„œë§Œ ê¸°ì¡´ ë§ˆìŠ¤í‚¹ ë¡œì§ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        b_idx_unfinished = torch.where(unfinished_mask)[0]
        td_unfinished = td[b_idx_unfinished]
        # ì´ sub-batchì— ëŒ€í•œ ë§ˆìŠ¤í¬ë¥¼ ì„ì‹œë¡œ ìƒì„±
        mask_unfinished = torch.zeros(len(b_idx_unfinished), num_nodes, num_nodes, dtype=torch.bool, device=self.device)

        # Phase 0: ì•„ì§ ì—°ê²°ë˜ì§€ ì•Šì€ Loadë§Œ ì„ íƒ ê°€ëŠ¥
        phase0_mask = (td_unfinished["decoding_phase"].squeeze(-1) == 0)
        if phase0_mask.any():
            mask_unfinished[phase0_mask, :, 0] = td_unfinished["unconnected_loads_mask"][phase0_mask]

        # Phase 1: í˜„ì¬ ê²½ë¡œë¥¼ ì´ì„ ë¶€ëª¨ ë…¸ë“œ ì„ íƒ
        phase1_mask = ~phase0_mask
        if phase1_mask.any():
            # Phase 1ì— í•´ë‹¹í•˜ëŠ” sub-batchë¥¼ ë‹¤ì‹œ ì¶”ì¶œ
            b_idx_p1_in_unfinished = torch.where(phase1_mask)[0]
            td_p1 = td_unfinished[b_idx_p1_in_unfinished]
            child_indices_p1 = td_p1["trajectory_head"].squeeze(-1)

            # (ê¸°ì¡´ì˜ ëª¨ë“  ì œì•½ì¡°ê±´ ê²€ì‚¬ ë¡œì§ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
            node_types = td_p1["nodes"][0, :, :FEATURE_INDEX["node_type"][1]].argmax(-1)
            parent_candidate_mask = (node_types == NODE_TYPE_IC) | (node_types == NODE_TYPE_BATTERY)
            can_be_parent = parent_candidate_mask.unsqueeze(0).expand(len(b_idx_p1_in_unfinished), -1).clone()

            # 2. ì‚¬ì´í´ ë°©ì§€
            ancestor_mask = self._trace_path_batch(b_idx_p1_in_unfinished, child_indices_p1, td_p1["adj_matrix"])
            descendant_mask = self._trace_path_batch(b_idx_p1_in_unfinished, child_indices_p1, td_p1["adj_matrix"].transpose(-1, -2))
            path_mask = ancestor_mask | descendant_mask
            can_be_parent &= ~path_mask

            # 3. ì „ì•• í˜¸í™˜ì„± ê²€ì‚¬
            child_vin_min = td_p1["nodes"][:, child_indices_p1, FEATURE_INDEX["vin_min"]]
            child_vin_max = td_p1["nodes"][:, child_indices_p1, FEATURE_INDEX["vin_max"]]
            parent_vout_min = td_p1["nodes"][:, :, FEATURE_INDEX["vout_min"]]
            parent_vout_max = td_p1["nodes"][:, :, FEATURE_INDEX["vout_max"]]
            is_voltage_compatible = (parent_vout_min <= child_vin_max.unsqueeze(1)) & \
                                    (parent_vout_max >= child_vin_min.unsqueeze(1))
            can_be_parent &= is_voltage_compatible


            # << í•µì‹¬ ìˆ˜ì •: ì „ë¥˜ í•œê³„ ê²€ì‚¬ ë¡œì§ ë‹¨ìˆœí™” ë° ìˆ˜ì • >>
            # 4. ì „ë¥˜ í•œê³„ ê²€ì‚¬
            # í˜„ì¬ ë§Œë“¤ê³  ìˆëŠ” ê²½ë¡œ(trajectory)ì— ì†í•œ ëª¨ë“  ë…¸ë“œì˜ ì „ë¥˜ ì†Œëª¨ëŸ‰ í•©ê³„ë¥¼ êµ¬í•©ë‹ˆë‹¤.
            current_path_mask = self._trace_path_batch(b_idx_p1_in_unfinished, child_indices_p1, td_p1["adj_matrix"])
            path_total_current = (td_p1["nodes"][:, :, FEATURE_INDEX["current_active"]] * current_path_mask).sum(dim=1)
            
            # ê° ì ì¬ì  ë¶€ëª¨ ICê°€ ì´ë¯¸ ì†Œëª¨í•˜ê³  ìˆëŠ” ì „ë¥˜ëŸ‰(`ic_current_draw`)ì—,
            # ìƒˆë¡œìš´ ê²½ë¡œì˜ ì „ë¥˜ëŸ‰ì„ ë”í•´ ì˜ˆìƒ ì†Œëª¨ëŸ‰ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
            prospective_draw = td_p1["ic_current_draw"] + path_total_current.unsqueeze(1)
            parent_limits = td_p1["nodes"][:, :, FEATURE_INDEX["i_limit"]]
            
            # ì˜ˆìƒ ì†Œëª¨ëŸ‰ì´ ë¶€ëª¨ì˜ í•œê³„ë¥¼ ë„˜ì§€ ì•Šê±°ë‚˜, ë¶€ëª¨ì˜ í•œê³„ê°€ 0(ë¬´í•œëŒ€)ì¸ ê²½ìš°ì—ë§Œ í—ˆìš©í•©ë‹ˆë‹¤.
            can_be_parent &= (prospective_draw <= parent_limits) | (parent_limits == 0)
        # << ìˆ˜ì • ë >>
            # 5. ê¸°íƒ€ ì œì•½ì¡°ê±´ (Independent Rail, Power Sequence)
            constraints, loads_info, node_names = self.generator.config.constraints, self.generator.config.loads, self.generator.config.node_names
            
            head_load_idx = child_indices_p1 - (1 + len(self.generator.config.available_ics))

            for idx in range(len(td_p1)):
                current_head_load_idx = head_load_idx[idx]
                if 0 <= current_head_load_idx < len(loads_info):
                    load = loads_info[current_head_load_idx]
                    rail_type = load.get("independent_rail_type")

                    if rail_type:
                        is_not_battery_mask = torch.ones(num_nodes, dtype=torch.bool, device=self.device)
                        is_not_battery_mask[0] = False

                        if rail_type == "exclusive_supplier":
                            # td_p1ì—ì„œ í˜„ì¬ idxì— í•´ë‹¹í•˜ëŠ” adj_matrixë¥¼ ì‚¬ìš©
                            no_existing_children_mask = td_p1["adj_matrix"][idx].sum(dim=1) == 0
                            can_be_parent[idx] &= (no_existing_children_mask | ~is_not_battery_mask)
                        elif rail_type == "exclusive_path":
                            less_than_two_children_mask = td_p1["adj_matrix"][idx].sum(dim=1) <= 1
                            can_be_parent[idx] &= (less_than_two_children_mask | ~is_not_battery_mask)
            
            ancestors = td_p1["adj_matrix"].clone().to(self.device) 
            for _ in range(num_nodes):
                ancestors = ancestors | (ancestors.float() @ ancestors.float()).bool()
                
            for seq in constraints.get("power_sequences", []):
                if seq.get("f") != 1: continue
                j_name, k_name = seq.get("j"), seq.get("k")
                if j_name not in node_names or k_name not in node_names: continue
                j_idx, k_idx = node_names.index(j_name), node_names.index(k_name)
                is_head_k_mask = child_indices_p1 == k_idx
                if is_head_k_mask.any():
                    can_be_parent[is_head_k_mask] &= ~ancestors[is_head_k_mask, :, j_idx]
            
            mask_unfinished_p1 = mask_unfinished[phase1_mask]
            mask_unfinished_p1[b_idx_p1_arange, child_indices_p1, :] = can_be_parent
            mask_unfinished[phase1_mask] = mask_unfinished_p1

        mask[unfinished_mask] = mask_unfinished


        return mask
    

    
    def get_reward(self, td: TensorDict, timed_out: torch.Tensor) -> torch.Tensor:
        """
        Calculates the reward based on the final state of the power tree.
        The reward is the negative of the total cost of used ICs.
        This function is called only when an episode is done.
        """
        reward = torch.zeros(td.batch_size[0], device=self.device)
        done = td["done"].squeeze(-1)
        
        # ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œëœ ê²½ìš°
        done_success = done & ~timed_out
        if done_success.any():
            is_used_mask = td["adj_matrix"][done_success].any(dim=1) | td["adj_matrix"][done_success].any(dim=2)
            node_costs = td["nodes"][done_success, :, FEATURE_INDEX["cost"]]
            ic_mask = td["nodes"][done_success, :, FEATURE_INDEX["node_type"][0] + NODE_TYPE_IC] == 1
            used_ic_mask = is_used_mask & ic_mask
            total_cost = (node_costs * used_ic_mask).sum(dim=-1)
            reward[done_success] = -total_cost

        # ğŸ’¡ *** ì—¬ê¸°ê°€ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ì…ë‹ˆë‹¤ (2/2) ***
        # ì‹œê°„ ì´ˆê³¼ë¡œ ì‹¤íŒ¨í•œ ê²½ìš° íŒ¨ë„í‹°ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.
        if timed_out.any():
            # ì—°ê²°í•˜ì§€ ëª»í•œ Loadì˜ ìˆ˜ë§Œí¼ í° íŒ¨ë„í‹°ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.
            unconnected_loads = td["unconnected_loads_mask"][timed_out].sum(dim=1).float()
            reward[timed_out] -= unconnected_loads * 10.0 # íŒ¨ë„í‹° ê°’
            
        return reward